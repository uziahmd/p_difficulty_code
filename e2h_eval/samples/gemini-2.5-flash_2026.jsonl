{"task_id": "E2H_CF1031A", "completion": "def solve():\n    w, h, k = map(int, input().split())\n\n    total_gilded_cells = 0\n\n    for i in range(k):\n        current_w = w - 4 * i\n        current_h = h - 4 * i\n\n        if current_w <= 0 or current_h <= 0:\n            break\n\n        # Calculate cells for the current ring\n        # A ring of size current_w x current_h has:\n        # 2 * current_w (top and bottom rows)\n        # 2 * (current_h - 2) (left and right columns, excluding corners already counted)\n        gilded_cells_in_ring = 2 * current_w + 2 * (current_h - 2)\n        total_gilded_cells += gilded_cells_in_ring\n\n    print(total_gilded_cells)\n\nif __name__ == '__main__':\n    solve()"}
{"task_id": "E2H_CF404A", "completion": "def solve():\n    n = int(input())\n    grid = [input() for _ in range(n)]\n\n    if n == 0:\n        print(\"NO\")\n        return\n\n    diag_char = grid[0][0]\n    other_char = ''\n    \n    # Check if all diagonal characters are the same\n    for i in range(n):\n        if grid[i][i] != diag_char:\n            print(\"NO\")\n            return\n        if grid[i][n - 1 - i] != diag_char:\n            print(\"NO\")\n            return\n\n    # Check all other characters\n    for r in range(n):\n        for c in range(n):\n            if r == c or r == n - 1 - c:  # On a diagonal\n                if grid[r][c] != diag_char:\n                    print(\"NO\")\n                    return\n            else:  # Not on a diagonal\n                if other_char == '':\n                    other_char = grid[r][c]\n                elif grid[r][c] != other_char:\n                    print(\"NO\")\n                    return\n    \n    # Check if diag_char and other_char are different\n    if other_char == '': # This can happen if n=1. For n=1, it should be YES.\n                         # But problem states n >= 3.\n                         # If n >= 3, there will always be 'other' characters.\n        print(\"NO\") # Should not happen for n>=3\n        return\n\n    if diag_char == other_char:\n        print(\"NO\")\n        return\n\n    print(\"YES\")\n\nsolve()"}
{"task_id": "E2H_CF492B", "completion": "def solve():\n    n, l = map(int, input().split())\n    a = list(map(int, input().split()))\n    a.sort()\n\n    max_gap = 0\n    for i in range(1, n):\n        max_gap = max(max_gap, a[i] - a[i-1])\n\n    d1 = max_gap / 2.0\n    d2 = a[0] - 0\n    d3 = l - a[-1]\n\n    result = max(d1, d2, d3)\n    print(f\"{result:.10f}\")\n\nsolve()"}
{"task_id": "E2H_CF173A", "completion": "import sys\n\ndef solve():\n    lines = sys.stdin.readlines()\n    n = int(lines[0].strip())\n    a_str = lines[1].strip()\n    b_str = lines[2].strip()\n\n    m = len(a_str)\n    k = len(b_str)\n\n    def get_winner(choice1, choice2):\n        if choice1 == choice2:\n            return 0  # Draw\n        if (choice1 == 'R' and choice2 == 'S') or \\\n           (choice1 == 'S' and choice2 == 'P') or \\\n           (choice1 == 'P' and choice2 == 'R'):\n            return 1  # Player 1 wins\n        return 2  # Player 2 wins\n\n    # Calculate losses for one full cycle of (a_str, b_str)\n    # The length of this cycle is lcm(m, k)\n    from math import gcd\n    lcm = (m * k) // gcd(m, k)\n\n    nikephoros_losses_cycle = 0\n    polycarpus_losses_cycle = 0\n\n    for i in range(lcm):\n        nikephoros_choice = a_str[i % m]\n        polycarpus_choice = b_str[i % k]\n        winner = get_winner(nikephoros_choice, polycarpus_choice)\n        if winner == 2:\n            nikephoros_losses_cycle += 1\n        elif winner == 1:\n            polycarpus_losses_cycle += 1\n\n    # Calculate total losses based on full cycles\n    num_full_cycles = n // lcm\n    nikephoros_total_losses = num_full_cycles * nikephoros_losses_cycle\n    polycarpus_total_losses = num_full_cycles * polycarpus_losses_cycle\n\n    # Calculate losses for the remaining rounds\n    remaining_rounds = n % lcm\n    for i in range(remaining_rounds):\n        nikephoros_choice = a_str[i % m]\n        polycarpus_choice = b_str[i % k]\n        winner = get_winner(nikephoros_choice, polycarpus_choice)\n        if winner == 2:\n            nikephoros_total_losses += 1\n        elif winner == 1:\n            polycarpus_total_losses += 1\n\n    sys.stdout.write(f\"{nikephoros_total_losses} {polycarpus_total_losses}\\n\")\n\nsolve()"}
{"task_id": "E2H_CF1141D", "completion": "import sys\n\ndef solve():\n    n = int(sys.stdin.readline())\n    l_str = sys.stdin.readline().strip()\n    r_str = sys.stdin.readline().strip()\n\n    l_indices = [[] for _ in range(27)]  # 0-25 for 'a'-'z', 26 for '?'\n    r_indices = [[] for _ in range(27)]\n\n    for i in range(n):\n        char_code = ord(l_str[i]) - ord('a') if l_str[i] != '?' else 26\n        l_indices[char_code].append(i + 1)\n        \n        char_code = ord(r_str[i]) - ord('a') if r_str[i] != '?' else 26\n        r_indices[char_code].append(i + 1)\n\n    pairs = []\n\n    # 1. Exact matches (specific color with specific color)\n    for char_code in range(26):\n        while l_indices[char_code] and r_indices[char_code]:\n            pairs.append((l_indices[char_code].pop(), r_indices[char_code].pop()))\n\n    # 2. Left '?' with specific right colors\n    # Iterate through specific right colors\n    for char_code in range(26):\n        while l_indices[26] and r_indices[char_code]:\n            pairs.append((l_indices[26].pop(), r_indices[char_code].pop()))\n\n    # 3. Right '?' with specific left colors\n    # Iterate through specific left colors\n    for char_code in range(26):\n        while l_indices[char_code] and r_indices[26]:\n            pairs.append((l_indices[char_code].pop(), r_indices[26].pop()))\n\n    # 4. Left '?' with Right '?'\n    while l_indices[26] and r_indices[26]:\n        pairs.append((l_indices[26].pop(), r_indices[26].pop()))\n\n    sys.stdout.write(str(len(pairs)) + '\\n')\n    for l_idx, r_idx in pairs:\n        sys.stdout.write(f\"{l_idx} {r_idx}\\n\")\n\nsolve()"}
{"task_id": "E2H_CF822C", "completion": "import sys\n\ndef solve():\n    n, x = map(int, sys.stdin.readline().split())\n    vouchers = []\n    for _ in range(n):\n        l, r, cost = map(int, sys.stdin.readline().split())\n        vouchers.append((l, r, cost))\n\n    vouchers.sort()\n\n    min_cost = float('inf')\n\n    # Max coordinate for l or r is 2 * 10^5\n    MAX_COORD = 2 * 10**5\n\n    # min_cost_for_duration[duration][end_day] stores the minimum cost of a voucher\n    # with given duration that ends on or before end_day.\n    # This structure is not efficient enough.\n    # We need something that can query min cost for a given duration and ending day.\n\n    # Let's group vouchers by their start day\n    vouchers_by_start = [[] for _ in range(MAX_COORD + 2)]\n    for l, r, cost in vouchers:\n        vouchers_by_start[l].append((r, cost, r - l + 1))\n\n    # Let's group vouchers by their end day\n    vouchers_by_end = [[] for _ in range(MAX_COORD + 2)]\n    for l, r, cost in vouchers:\n        vouchers_by_end[r].append((l, cost, r - l + 1))\n\n    # We need to efficiently query for a voucher (l, r, cost) with duration D1\n    # and another voucher (l', r', cost') with duration D2 such that D1 + D2 = x\n    # and r < l' or r' < l.\n\n    # Option 1: Iterate through all pairs. Too slow (N^2).\n    # Option 2: Fix one voucher, search for the second.\n\n    # Let's iterate through vouchers and consider each as the first voucher (l1, r1, cost1).\n    # We need to find a second voucher (l2, r2, cost2) such that:\n    # 1. r1 < l2 (first voucher ends before second starts)\n    # 2. (r1 - l1 + 1) + (r2 - l2 + 1) = x\n    # 3. cost1 + cost2 is minimized.\n\n    # To do this efficiently, we can precompute minimum costs for vouchers\n    # based on their duration and end day.\n\n    # min_cost_for_duration_ending_at_or_before[duration][end_day]\n    # This still requires too much memory if duration is a dimension.\n    # A duration can be up to MAX_COORD.\n\n    # Let's use a data structure to store minimum costs for each duration.\n    # `min_cost_for_duration[duration]` will store the minimum cost for a voucher\n    # of that specific duration.\n    # This structure needs to be updated as we sweep through possible `r1` values.\n\n    # `min_cost_for_duration[d]` stores the minimum cost of a voucher\n    # with duration `d` that has been processed so far (i.e., its `r` is <= current `r1`).\n    # Initialize with infinity.\n    min_cost_for_duration = [float('inf')] * (MAX_COORD + 1)\n\n    # Iterate `r1` from 1 to MAX_COORD.\n    # For each `r1`, we consider all vouchers that end at `r1`.\n    # These vouchers are candidates for the \"first\" voucher.\n    # We also consider all vouchers that start at `r1 + 1`.\n    # These vouchers are candidates for the \"second\" voucher, if the first voucher ends at `r1`.\n\n    # Let's iterate through possible `r_end_1` values (the end day of the first voucher).\n    # When we are at `r_end_1`:\n    # 1. Add all vouchers that end at `r_end_1` to our pool of available \"first\" vouchers.\n    #    For each such voucher (l, r_end_1, cost), update `min_cost_for_duration[r_end_1 - l + 1] = min(current_value, cost)`.\n    # 2. Consider all vouchers that start at `r_end_1 + 1`. These are potential \"second\" vouchers.\n    #    For each such voucher (l_start_2, r_end_2, cost2) where l_start_2 = r_end_1 + 1:\n    #    Calculate its duration `d2 = r_end_2 - l_start_2 + 1`.\n    #    We need a first voucher with duration `d1 = x - d2`.\n    #    If `d1 > 0` and `d1 <= MAX_COORD`, we can query `min_cost_for_duration[d1]`.\n    #    If `min_cost_for_duration[d1]` is not infinity, then we have a valid pair.\n    #    Update `min_cost = min(min_cost, min_cost_for_duration[d1] + cost2)`.\n\n    # This approach is good. The `min_cost_for_duration` array needs to store the minimum cost\n    # of a voucher with a given duration that has *already ended*.\n\n    # `current_min_costs_by_duration[d]` stores the minimum cost of a voucher\n    # with duration `d` that has an end day `r` such that `r < current_l_start_2`.\n    current_min_costs_by_duration = [float('inf')] * (MAX_COORD + 1)\n\n    # Iterate through all possible start days `l_start_2` for the second voucher.\n    # `l_start_2` can range from 1 to MAX_COORD.\n    # The first voucher must end at `r_end_1 = l_start_2 - 1`.\n    for l_start_2 in range(1, MAX_COORD + 1):\n        r_end_1 = l_start_2 - 1\n\n        # Step 1: Add all vouchers that end at `r_end_1` to our pool of available \"first\" vouchers.\n        # These vouchers become eligible for `current_min_costs_by_duration`.\n        if r_end_1 >= 1:\n            for l1, cost1, duration1 in vouchers_by_end[r_end_1]:\n                current_min_costs_by_duration[duration1] = min(current_min_costs_by_duration[duration1], cost1)\n\n        # Step 2: Consider all vouchers that start at `l_start_2`. These are potential \"second\" vouchers.\n        for r2, cost2, duration2 in vouchers_by_start[l_start_2]:\n            d1_required = x - duration2\n            if d1_required > 0 and d1_required <= MAX_COORD:\n                if current_min_costs_by_duration[d1_required] != float('inf'):\n                    min_cost = min(min_cost, current_min_costs_by_duration[d1_required] + cost2)\n\n    if min_cost == float('inf'):\n        sys.stdout.write(\"-1\\n\")\n    else:\n        sys.stdout.write(str(min_cost) + \"\\n\")\n\nsolve()"}
{"task_id": "E2H_CF1846E2", "completion": "import sys\n\ndef solve():\n    n = int(sys.stdin.readline())\n\n    if n < 7:\n        sys.stdout.write(\"NO\\n\")\n        return\n\n    # Case 1: m = 2 (2 levels of expansion)\n    # Total vertices = 1 + k + k*k = 1 + k + k^2\n    # We need to find if n = 1 + k + k^2 for some k > 1.\n    # k^2 + k + (1 - n) = 0\n    # Using quadratic formula: k = (-1 +/- sqrt(1 - 4*(1-n))) / 2\n    # k = (-1 +/- sqrt(1 - 4 + 4n)) / 2\n    # k = (-1 +/- sqrt(4n - 3)) / 2\n    # For k to be an integer > 1, 4n - 3 must be a perfect square, say s^2.\n    # s = sqrt(4n - 3)\n    # Then k = (-1 + s) / 2\n    # We need s to be an integer, s > 0, and (-1 + s) / 2 > 1.\n    # This means -1 + s > 2, so s > 3.\n    # Also, s must be odd for (-1 + s) to be even.\n    \n    discriminant = 4 * n - 3\n    s_approx = int(discriminant**0.5)\n    \n    for s in range(max(1, s_approx - 2), s_approx + 3):\n        if s * s == discriminant:\n            if s > 3 and (s - 1) % 2 == 0:\n                k = (s - 1) // 2\n                if k > 1:\n                    sys.stdout.write(\"YES\\n\")\n                    return\n\n    # Case 2: m >= 3 (3 or more levels of expansion)\n    # Total vertices = 1 + k + k^2 + ... + k^(m-1) = (k^m - 1) / (k - 1)\n    # We are looking for n = (k^m - 1) / (k - 1) for some k > 1 and m >= 3.\n    # This is equivalent to n * (k - 1) = k^m - 1.\n    # Since k >= 2, m >= 3:\n    # Smallest n for m=3, k=2 is (2^3 - 1) / (2 - 1) = 7.\n    # Smallest n for m=3, k=3 is (3^3 - 1) / (3 - 1) = 26 / 2 = 13.\n    # Smallest n for m=4, k=2 is (2^4 - 1) / (2 - 1) = 15.\n    \n    # Iterate over possible values of m.\n    # The maximum value of m is relatively small because k >= 2.\n    # If k = 2, n = 2^m - 1. So 2^m = n + 1. m = log2(n + 1).\n    # If n = 10^18, m approx log2(10^18) = 18 * log2(10) approx 18 * 3.32 = 59.79.\n    # So m goes up to about 60.\n    \n    # If k = 3, n = (3^m - 1) / 2. 3^m = 2n + 1. m = log3(2n + 1).\n    # If n = 10^18, m approx log3(2 * 10^18) = log3(2) + 18 * log3(10) approx 0.63 + 18 * 2.09 = 0.63 + 37.62 = 38.25.\n    # So m goes up to about 40 for k=3.\n    \n    # If k = 10^9, m = 3. n = 1 + k + k^2 approx k^2 = (10^9)^2 = 10^18.\n    # So m can be small (e.g., 3) for large k.\n    \n    # The maximum value of m is about 60.\n    for m in range(3, 61):\n        # We need to find k such that n = (k^m - 1) / (k - 1)\n        # n * (k - 1) = k^m - 1\n        # This is equivalent to finding integer root k > 1 for the polynomial:\n        # P(k) = k^m - n*k + (n - 1) = 0\n        \n        # We can use binary search for k.\n        # k must be at least 2.\n        # Upper bound for k:\n        # If m=3, n = 1 + k + k^2. So k^2 < n. k < sqrt(n).\n        # If n = 10^18, k < 10^9.\n        # A safe upper bound for k is n^(1/(m-1)).\n        # k^m - 1 approx k^m. n approx k^m / (k-1).\n        # If k is large, n approx k^(m-1). So k approx n^(1/(m-1)).\n        # For m=3, k approx n^(1/2). For m=60, k approx n^(1/59).\n        # n^(1/59) for n=10^18 is (10^18)^(1/59) = 10^(18/59) approx 10^0.3 = 2.\n        # So k can be large for small m, and small for large m.\n        \n        # Binary search range for k: [2, n^(1/2) + 2]\n        # A more practical upper bound: if k^m - 1 > n*(k-1), then k is too large.\n        # k^m - 1 > n*k - n\n        # k^m - n*k + n - 1 > 0\n        # For k=2, 2^m - 2n + n - 1 = 2^m - n - 1. If this is positive, k=2 is too large.\n        # If k=2, n = 2^m - 1.\n        # If n > 2^m - 1, then k must be > 2.\n        # If n < 2^m - 1, then k must be < 2 (not possible as k >= 2).\n        # So for a given m, if n < 2^m - 1, no solution for that m.\n        \n        # Lower bound for k is 2.\n        # Upper bound for k: n = (k^m - 1)/(k-1) > k^(m-1). So k < n^(1/(m-1)).\n        # A safe upper bound is min(2 * 10**9, int(n**(1.0/(m-1))) + 3).\n        # 10**18 is the max n. For m=3, k approx sqrt(10^18) = 10^9.\n        # For m=4, k approx (10^18)^(1/3) = 10^6.\n        # For m=5, k approx (10^18)^(1/4) = 10^4.5 approx 31622.\n        # Max k is 10^9.\n        \n        low = 2\n        high = min(2 * 10**9, int(n**(1.0/(m-1))) + 3) # Upper bound for k\n        \n        # Check high value specifically to avoid overflow in high * high * ...\n        # (k^m - 1) / (k - 1) = n\n        # This is equivalent to k^m - 1 = n * (k - 1)\n        # If k is too large, k^m - 1 will overflow.\n        # So we must cap high at a value where k^m does not overflow.\n        # For k=2*10^9, m=3, k^m = (2*10^9)^3 = 8 * 10^27, which overflows standard 64-bit int.\n        # Python integers handle arbitrary size, but the calculations are slow.\n        # We need to be careful with k^m.\n        # n is up to 10^18.\n        # If k^m - 1 = n * (k - 1), then k^m approx n * k.\n        # k^(m-1) approx n.\n        # So k approx n^(1/(m-1)).\n        # So k cannot exceed n^(1/(m-1)) significantly.\n        # Let's use a tighter upper bound for binary search.\n        # If m=3, k approx sqrt(n). Max sqrt(10^18) = 10^9.\n        # If m=4, k approx (10^18)^(1/3) = 10^6.\n        # The largest k occurs for m=3. So high can be around 10^9.\n        # Let's set high to 10^9 + 7 (a bit more than 10^9).\n        \n        # Let's use a more robust upper bound for k for binary search.\n        # k^m - 1 = n(k-1)\n        # k^m - nk + n - 1 = 0\n        # If k >= 2:\n        # k^(m-1) < n. So k < n^(1/(m-1)).\n        # For m=3, k < n^(1/2). Max k < 10^9.\n        # For m=60, k < n^(1/59). Max k < (10^18)^(1/59) approx 2.\n        # So the maximum k to check is 10^9 + 2.\n        \n        high = int(n**(1.0/(m-1))) + 2 if m > 1 else 2\n        high = min(high, 10**9 + 7) # Cap high to prevent k^m overflow for m=3\n        \n        # If n is very large and m is small, k could be large.\n        # Example: n = 10^18, m = 3. k approx 10^9.\n        # k^m is (10^9)^3 = 10^27. This will not overflow Python's arbitrary precision integers,\n        # but it will be slow.\n        # The number of iterations in binary search is log(high - low).\n        # log(10^9) approx 30.\n        # So for each m, we do 30 iterations. 60 * 30 = 1800 iterations.\n        # In each iteration, we calculate k^m.\n        # k^m can be calculated efficiently using pow(k, m).\n        \n        found_k = False\n        while low <= high:\n            mid = (low + high) // 2\n            if mid < 2: # k must be > 1\n                low = 2\n                continue\n            \n            # Calculate (mid^m - 1) / (mid - 1)\n            # Check for overflow or too large values for mid^m\n            # If mid^(m-1) > n, then mid is too large.\n            # This is a better check than mid^m.\n            # mid^(m-1) can be up to 10^18 for m=3.\n            # mid^m can be up to 10^18 * 10^9 = 10^27.\n            \n            val = 0\n            try:\n                # Calculate sum of geometric series: 1 + mid + mid^2 + ... + mid^(m-1)\n                # To avoid overflow for mid^m, we can check mid^(m-1) first.\n                # If mid^(m-1) > n, then sum will be > n.\n                # If mid^(m-1) is already > n, it's too big.\n                # Use a threshold slightly larger than n to avoid floating point issues.\n                if m > 1:\n                    if mid > 1:\n                        # Direct calculation of sum of geometric series\n                        # k^m - 1 / k - 1\n                        # If mid is large, mid^m can be huge.\n                        # We need to check if mid^(m-1) exceeds n.\n                        # If mid > n^(1/(m-1)), then mid^(m-1) > n.\n                        # This check is done by `high` bound.\n                        # But what if mid^(m-1) is just below n, but mid^m overflows?\n                        # Python handles large integers, so overflow is not a problem.\n                        # Performance might be an issue.\n                        \n                        # Let's compute term by term and stop if it exceeds n.\n                        current_sum = 1\n                        current_power_of_k = 1\n                        for _ in range(1, m): # From k^1 to k^(m-1)\n                            # Check for potential overflow of current_power_of_k * mid\n                            # if current_power_of_k > n // mid (approx)\n                            # This avoids actual overflow if current_power_of_k * mid\n                            # were to exceed system limits (not an issue in Python, but good practice).\n                            # If current_power_of_k > n (since n is the target sum)\n                            # Or if current_power_of_k * mid would exceed n\n                            if current_power_of_k > n // mid: # Avoids current_power_of_k * mid > n.\n                                current_sum = n + 1 # Mark as too large\n                                break\n                            current_power_of_k *= mid\n                            current_sum += current_power_of_k\n                            if current_sum > n: # If sum exceeds n, it's too large\n                                break\n                        val = current_sum\n                    else: # mid == 1, not allowed as k > 1\n                        val = 0 # Invalid k\n                else: # m = 1, not allowed as m >= 3\n                    val = 0\n            except OverflowError:\n                val = n + 1 # Mark as too large\n            \n            if val == n:\n                found_k = True\n                break\n            elif val < n:\n                low = mid + 1\n            else: # val > n\n                high = mid - 1\n        \n        if found_k:\n            sys.stdout.write(\"YES\\n\")\n            return\n\n    sys.stdout.write(\"NO\\n\")\n\nnum_test_cases = int(sys.stdin.readline())\nfor _ in range(num_test_cases):\n    solve()"}
{"task_id": "E2H_CF270E", "completion": "import sys\n\ndef solve():\n    n, m = map(int, sys.stdin.readline().split())\n\n    adj = [[] for _ in range(n + 1)]\n    edges_input = []\n    for i in range(m):\n        u, v, c = map(int, sys.stdin.readline().split())\n        adj[u].append((v, c, i))\n        adj[v].append((u, c, i))\n        edges_input.append((u, v, c))\n\n    ans = [-1] * m\n    visited_edges = [False] * m\n    balance = [0] * (n + 1)\n    \n    # DFS to determine directions\n    # We want to direct edges away from 1 and towards n\n    # The crucial observation is that the graph without cycles\n    # implies that it's a DAG. A max flow in a DAG can be found\n    # by topological sort. Here, we're given the flow values,\n    # and need to orient them.\n    # The condition \"vertex with number 1 has no incoming edges\"\n    # means all edges connected to 1 must be outgoing.\n    # We can use a DFS from node 1 to orient edges.\n    # The balance array will help us maintain the flow conservation.\n    # balance[v] = sum of incoming flow - sum of outgoing flow\n    # For intermediate vertices (1 < v < n), balance[v] must be 0.\n    # For vertex 1, balance[1] <= 0 (all outgoing).\n    # For vertex n, balance[n] >= 0 (all incoming).\n\n    # The problem statement also says \"the obtained directed graph does not have cycles\".\n    # This is a strong hint. If we can build a DAG, a topological sort exists.\n    # A simple DFS from source (1) can help build a topological order and orient edges.\n    # However, the balance constraint is tricky.\n    # Let's try to orient edges such that flow goes from smaller topological order to larger.\n    # But we don't know the topological order yet.\n\n    # A common technique for such problems is to use a DFS and keep track of flow balance.\n    # For each node v (1 < v < n), its net flow must be 0.\n    # For node 1, all flow must be outgoing.\n    # For node n, all flow must be incoming.\n\n    # Let's try a DFS from node 1.\n    # We maintain `balance[u]` for each node `u`.\n    # When we traverse an edge (u, v) with capacity `c`:\n    # If we direct it u -> v: `balance[u] -= c`, `balance[v] += c`.\n    # If we direct it v -> u: `balance[v] -= c`, `balance[u] += c`.\n\n    # The \"no cycles\" condition is key. This implies a DAG.\n    # A standard way to ensure no cycles and satisfy flow conservation for intermediate nodes\n    # is to process nodes in a topological order.\n    # However, we don't have a topological order yet.\n    # The problem can be rephrased: for each node v (1 < v < n), the sum of flows on edges directed away from v\n    # must equal the sum of flows on edges directed towards v.\n    # This is equivalent to saying that `balance[v]` (net incoming flow) must be 0.\n\n    # Consider the total flow into vertex v, `in_flow[v]`, and total flow out of vertex v, `out_flow[v]`.\n    # For 1 < v < n, `in_flow[v] == out_flow[v]`.\n    # For v = 1, `in_flow[1] == 0`.\n    # For v = n, `out_flow[n] == 0`.\n\n    # Let's try a different approach. The problem asks for *any* valid solution.\n    # The \"no cycles\" condition is often handled by building a topological sort or by\n    # ensuring that we only add edges from visited to unvisited nodes in a DFS/BFS.\n    # However, this doesn't directly handle the balance.\n\n    # The total flow out of 1 must equal the total flow into n.\n    # Let's calculate the total flow `F`.\n    # `F = sum of c for all edges connected to 1, if directed away from 1`.\n    # `F = sum of c for all edges connected to n, if directed towards n`.\n\n    # The key insight for these types of problems is often a greedy approach or a specific traversal.\n    # If we use a DFS, when we traverse an edge (u, v), we need to decide its direction.\n    # If we direct u -> v, then u contributes `c` to `balance[v]` and `u` loses `c` from its \"available\" flow.\n    # If we direct v -> u, then v contributes `c` to `balance[u]` and `v` loses `c` from its \"available\" flow.\n\n    # Let's try a DFS from node 1.\n    # `dfs(u, p)`: `u` is current node, `p` is parent.\n    # When we visit `u`, we try to satisfy its flow balance.\n    # `current_flow_balance[u]` will store the net flow that needs to be directed *out* of `u`\n    # (or net flow that has already been directed *into* `u` from its children).\n    # Initially, `current_flow_balance[u]` is 0 for all `u`.\n\n    # The problem implies that a valid maximum flow already exists with these magnitudes.\n    # This means the total flow from 1 equals the total flow to n.\n    # Let `total_flow_sum` be the sum of all `c_i` in the graph. This is not the max flow.\n\n    # A common approach for reconstructing flow directions is to use a DFS/BFS.\n    # We can try to build a \"topological-like\" order from node 1.\n    # For each node `u`, we want `sum(in_flow) == sum(out_flow)` for `1 < u < n`.\n    # Let `balance[u]` be the amount of flow that *must* exit `u` to satisfy conservation.\n    # Initially, `balance[1]` is the total flow, `balance[n]` is -total flow.\n    # All other `balance[u]` are 0.\n\n    # This is tricky because we don't know the total flow.\n    # Let's consider the balance values:\n    # `balance[v]` = sum of `c_i` for edges `(x, v)` directed `x -> v`\n    #              - sum of `c_i` for edges `(v, y)` directed `v -> y`\n\n    # For `1 < v < n`, `balance[v] = 0`.\n    # For `v = 1`, `balance[1] <= 0`. (All edges from 1 must be outgoing, so it's `0 - total_flow_out_of_1`).\n    # For `v = n`, `balance[n] >= 0`. (All edges to n must be incoming, so it's `total_flow_into_n - 0`).\n    # And `total_flow_out_of_1 == total_flow_into_n`.\n\n    # Let's use a DFS that accumulates flow.\n    # `current_net_flow[u]` will store the net flow that has entered `u` from its children in the DFS tree.\n    # When `dfs(u, p)` finishes, `current_net_flow[u]` will be the sum of flows that *must* exit `u`\n    # to balance the flows from its children.\n    # If `current_net_flow[u] > 0`, it means `u` has received `current_net_flow[u]` from its children,\n    # and this flow needs to be sent up to `p` (or out of `u` if `u` is 1).\n    # If `current_net_flow[u] < 0`, it means `u` has sent `abs(current_net_flow[u])` to its children,\n    # and `u` needs to receive this amount from `p` (or from itself if `u` is 1).\n\n    # The problem states \"vertex with number 1 has no incoming edges\".\n    # This implies that all edges connected to 1 must be directed away from 1.\n    # Let's initialize `balance[1]` to 0. When we traverse `1 -> v`, we subtract `c` from `balance[1]`\n    # and add `c` to `balance[v]`.\n    # This approach is usually done with a DFS from node 1.\n\n    # A common strategy for these problems is to use a DFS starting from node 1.\n    # For each node `u`, we compute its \"excess\" flow.\n    # `excess[u]` = sum of `c_i` of edges `(u, v)` where `v` is a child in DFS tree, directed `u -> v`\n    #              - sum of `c_i` of edges `(v, u)` where `v` is a child in DFS tree, directed `v -> u`\n    # When we return from `dfs(v, u)`:\n    #   `excess[u] += excess[v]`.\n    #   If `excess[v] > 0`, it means `v` has `excess[v]` flow that needs to be sent out.\n    #     We direct `u <- v` (flow `v -> u`). `ans[edge_idx] = 1`. `excess[u] += c`.\n    #   If `excess[v] < 0`, it means `v` needs `abs(excess[v])` flow.\n    #     We direct `u -> v` (flow `u -> v`). `ans[edge_idx] = 0`. `excess[u] -= c`.\n    # This works for intermediate nodes.\n    # For node `n`, it's the sink, so all flow must be incoming.\n    # For node `1`, it's the source, so all flow must be outgoing.\n\n    # Let's define `current_flow[u]` as the net flow that *must* be sent *out* of `u`\n    # to satisfy the conservation property for `u` and its subtree in the DFS tree.\n    # Initially, `current_flow[u] = 0` for all `u`.\n    # When `dfs(u, p)` is called:\n    #   For each neighbor `v` of `u` (that is not `p` and not visited):\n    #     `dfs(v, u, edge_idx)`\n    #     After `dfs(v, u, edge_idx)` returns, `current_flow[v]` contains the net flow\n    #     that needs to be sent *out* of `v`.\n    #     If `current_flow[v] > 0`: `v` has `current_flow[v]` excess flow.\n    #       This flow must be directed `v -> u`. So `ans[edge_idx] = 1`.\n    #       `current_flow[u] += current_flow[v]`.\n    #     If `current_flow[v] < 0`: `v` needs `abs(current_flow[v])` flow.\n    #       This flow must be directed `u -> v`. So `ans[edge_idx] = 0`.\n    #       `current_flow[u] += current_flow[v]`. (Subtracts from `u`'s outflow requirement).\n    #     If `current_flow[v] == 0`: This edge is not needed to balance the subtree.\n    #       This can happen if `v` is `n`. For `n`, `current_flow[n]` should be 0, meaning it can absorb all flow.\n    #       Or if `v` is an intermediate node that perfectly balances its subtree.\n    #       However, `current_flow[v]` will be `c` for edges to `n` if directed towards `n`.\n\n    # Let's redefine `current_flow[u]` as the total flow that *has entered* `u` from its children.\n    # When `dfs(u, p)` returns, `current_flow[u]` should represent the total flow that needs to leave `u` via `(u, p)`.\n    # For `u = n`, `current_flow[n]` should be the total flow entering `n`.\n    # For `u = 1`, `current_flow[1]` should be the total flow leaving `1`.\n\n    # Let `balance[u]` be the sum of flow values of edges incident to `u` that have been directed towards `u`\n    # minus the sum of flow values of edges incident to `u` that have been directed away from `u`.\n    # We want `balance[u] = 0` for `1 < u < n`.\n    # `balance[1] <= 0` (all outgoing from 1).\n    # `balance[n] >= 0` (all incoming to n).\n\n    # The key is that `balance[u]` represents the *net incoming flow* to `u`.\n    # When we do a DFS from 1:\n    # `dfs(u, parent_edge_idx)`:\n    #   `visited[u] = True`\n    #   `current_balance_for_u = 0`\n    #   For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n    #     If `idx` is `parent_edge_idx`: continue (don't go back to parent)\n    #     If `visited_edges[idx]`: continue (already processed this edge from other side, or parent edge)\n    #     `visited_edges[idx] = True`\n    #     `child_balance = dfs(v, idx)`\n    #     If `child_balance > 0`:\n    #       // `v` has an excess of `child_balance` flow that needs to leave `v`.\n    #       // This flow must come to `u`. So `v -> u`.\n    #       If `edges_input[idx]` is `(u, v, c)`: `ans[idx] = 1` (flow `v -> u`)\n    #       Else: `ans[idx] = 0` (flow `u -> v`, but we need `v -> u`, so it must be `v -> u` based on input `(v, u, c)`)\n    #       // This logic is confusing with `edges_input`. Let's use `u, v` from `adj` directly.\n    #       // If `adj[u]` has `(v, c, idx)`, and `ans[idx]` is 0, it means `u -> v`. If 1, `v -> u`.\n    #       // If `adj[v]` has `(u, c, idx)`, and `ans[idx]` is 0, it means `u -> v`. If 1, `v -> u`.\n    #       // Let's stick to `edges_input[idx] = (a, b, c)`.\n    #       // If `ans[idx] = 0`, then `a -> b`. If `ans[idx] = 1`, then `b -> a`.\n    #       current_balance_for_u += child_balance\n    #       if edges_input[idx][0] == u: # Original edge was (u, v), we want v -> u, so flip\n    #           ans[idx] = 1\n    #       else: # Original edge was (v, u), we want v -> u, so keep original direction\n    #           ans[idx] = 0\n    #     Else (`child_balance <= 0`):\n    #       // `v` needs `abs(child_balance)` flow. This flow must come from `u`. So `u -> v`.\n    #       current_balance_for_u += child_balance # This is subtraction\n    #       if edges_input[idx][0] == u: # Original edge was (u, v), we want u -> v, so keep original direction\n    #           ans[idx] = 0\n    #       else: # Original edge was (v, u), we want u -> v, so flip\n    #           ans[idx] = 1\n    #   // After visiting all children, `current_balance_for_u` is the net flow that needs to enter `u`\n    #   // from its parent `p` to balance `u` and its subtree.\n    #   // If `u` is `n`, it can absorb any flow, so its `current_balance_for_u` should be 0 effectively.\n    #   // If `u` is `1`, it's the source, it needs to send out flow.\n    #   // The total flow out of 1 is the total flow.\n\n    # This seems like a good approach. The `current_balance_for_u` represents the net flow that needs to be\n    # supplied *to* `u` from its parent to satisfy the flow conservation for `u` and its subtree.\n    # If `u` is `n`, it's the sink, it should effectively return `0` to its parent, meaning it can absorb\n    # whatever flow comes to it.\n    # If `u` is `1`, it's the source. It shouldn't receive any flow from a parent.\n    # The initial `balance[u]` should be 0 for `1 < u < n`.\n    # For `u = n`, we want `balance[n]` to be `sum of incoming flows`.\n    # For `u = 1`, we want `balance[1]` to be `sum of outgoing flows`.\n\n    # Let's simplify `balance[u]` to be the amount of flow that *must* exit `u` to satisfy conservation.\n    # If `balance[u]` is positive, `u` has an excess and needs to send it out.\n    # If `balance[u]` is negative, `u` needs to receive flow.\n\n    # The actual algorithm usually works like this:\n    # `dfs(u, p_edge_idx)` returns the net flow that *exits* `u` through the edge to `p`.\n    # `visited[u] = True`\n    # `flow_to_parent = 0`\n    # For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n    #   If `idx == p_edge_idx`: continue\n    #   If `visited[v]`: continue (this is a back edge, means cycle, but problem says no cycles in final graph.\n    #                      This means we only process tree edges in DFS.\n    #                      However, the graph is undirected, so we need to avoid going back to parent).\n    #   `child_flow = dfs(v, idx)`\n    #   // `child_flow` is the net flow that `v` sends to `u`.\n    #   // If `child_flow > 0`, `v` sends `child_flow` to `u`. Direction `v -> u`.\n    #   // If `child_flow < 0`, `v` needs `abs(child_flow)` from `u`. Direction `u -> v`.\n    #   // The edge `(u, v)` has flow `c`.\n    #   If `child_flow > 0`:\n    #     // `v` has an excess of `child_flow`. This flow must come to `u`. So `v -> u`.\n    #     // The edge `(u, v)` has flow `c`. `child_flow` should be equal to `c`.\n    #     // This implies that `dfs(v, idx)` returned `c`.\n    #     // `flow_to_parent += c`.\n    #     // Set direction `v -> u`.\n    #     if edges_input[idx][0] == u: ans[idx] = 1 # original was (u,v), want v->u\n    #     else: ans[idx] = 0 # original was (v,u), want v->u\n    #     flow_to_parent += c\n    #   Else: # `child_flow <= 0`\n    #     // `v` needs `abs(child_flow)`. This flow must come from `u`. So `u -> v`.\n    #     // `abs(child_flow)` should be equal to `c`.\n    #     // This implies that `dfs(v, idx)` returned `-c`.\n    #     // `flow_to_parent -= c`.\n    #     // Set direction `u -> v`.\n    #     if edges_input[idx][0] == u: ans[idx] = 0 # original was (u,v), want u->v\n    #     else: ans[idx] = 1 # original was (v,u), want u->v\n    #     flow_to_parent -= c\n\n    # This is still not quite right. `child_flow` is not just `c` or `-c`.\n    # `child_flow` is the accumulated net flow from the subtree rooted at `v`.\n    # The actual flow on edge `(u, v)` is `c`.\n\n    # Let's use `current_balance[u]` to store the sum of flows that *must* exit `u` from its children.\n    # `dfs(u, p_edge_idx)`:\n    #   `visited[u] = True`\n    #   `u_balance = 0` (represents net flow that needs to exit `u` to its parent)\n    #   For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n    #     If `idx == p_edge_idx`: continue\n    #     If `visited[v]`: continue (this is a back edge, we'll handle it later or it's implicitly handled by parent)\n    #     `v_subtree_balance = dfs(v, idx)`\n    #     If `v_subtree_balance > 0`:\n    #       # `v` and its subtree has an excess of `v_subtree_balance` flow.\n    #       # This flow must exit `v` through `(v, u)`. So `v -> u`.\n    #       # The edge `(u, v)` has capacity `c`. This means `v_subtree_balance` must be `c`.\n    #       # This implies `v_subtree_balance` is the flow on edge `(v,u)`.\n    #       if edges_input[idx][0] == u: ans[idx] = 1 # original (u,v), want v->u\n    #       else: ans[idx] = 0 # original (v,u), want v->u\n    #       u_balance += c # `u` receives `c` from `v`\n    #     Else: # `v_subtree_balance <= 0`\n    #       # `v` and its subtree needs `abs(v_subtree_balance)` flow.\n    #       # This flow must enter `v` through `(u, v)`. So `u -> v`.\n    #       # The edge `(u, v)` has capacity `c`. This means `abs(v_subtree_balance)` must be `c`.\n    #       if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n    #       else: ans[idx] = 1 # original (v,u), want u->v\n    #       u_balance -= c # `u` sends `c` to `v`\n    #   \n    #   // Special handling for node `n` (sink)\n    #   If `u == n`:\n    #     // The sink node `n` can absorb any amount of flow.\n    #     // It doesn't need to pass flow up to its parent.\n    #     // So, its contribution to `u_balance` (flow to parent) is 0.\n    #     return 0 # `n` effectively returns 0 to its parent.\n    #   \n    #   return u_balance\n\n    # This assumes that `v_subtree_balance` will always be `c` or `-c`.\n    # This is true if the flow on the edge `(u,v)` is `c`.\n    # Let `dfs(u, p)` return the net flow that *must* exit `u` to its parent `p`\n    # to satisfy flow conservation for `u` and its subtree.\n    # For `u=n`, this value should be 0, as `n` is a sink.\n    # For `u=1`, this value should be the total max flow, as `1` is a source.\n\n    # Let `current_flow_sum[u]` be the total flow that *has entered* `u` from its children.\n    # `dfs(u, p_edge_idx)`:\n    #   `visited[u] = True`\n    #   `current_flow_sum_for_u = 0`\n    #   For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n    #     If `idx == p_edge_idx`: continue\n    #     If `visited[v]`: continue\n    #     `child_flow_sum = dfs(v, idx)`\n    #     If `child_flow_sum > 0`: # `v` has `child_flow_sum` excess flow from its subtree\n    #       # This flow must come to `u` via `(v, u)`.\n    #       # The edge `(u, v)` has capacity `c`. So `child_flow_sum` must be `c`.\n    #       # Direction: `v -> u`.\n    #       if edges_input[idx][0] == u: ans[idx] = 1 # original (u,v), want v->u\n    #       else: ans[idx] = 0 # original (v,u), want v->u\n    #       current_flow_sum_for_u += c # `u` receives `c` from `v`\n    #     Else: # `child_flow_sum <= 0` # `v` needs `abs(child_flow_sum)` flow\n    #       # This flow must go from `u` to `v` via `(u, v)`.\n    #       # The edge `(u, v)` has capacity `c`. So `abs(child_flow_sum)` must be `c`.\n    #       # Direction: `u -> v`.\n    #       if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n    #       else: ans[idx] = 1 # original (v,u), want u->v\n    #       current_flow_sum_for_u -= c # `u` sends `c` to `v`\n    #\n    #   If `u == n`: # `n` is the sink, it absorbs all flow.\n    #     return 0 # No flow needs to be passed up to its parent.\n    #\n    #   return current_flow_sum_for_u\n\n    # This seems like a solid approach.\n    # The `visited` array ensures we traverse each edge once in the DFS tree.\n    # The `p_edge_idx` prevents going back to the immediate parent.\n    # The `ans` array stores the directions.\n\n    visited = [False] * (n + 1)\n\n    def dfs(u, p_edge_idx):\n        visited[u] = True\n        \n        # current_flow_sum_for_u: net flow that has been directed *into* u from its children\n        # (positive means net incoming, negative means net outgoing)\n        current_flow_sum_for_u = 0 \n\n        for v, c, idx in adj[u]:\n            if idx == p_edge_idx:\n                continue\n            if visited[v]:\n                # This is a back edge. Since the final graph must be a DAG,\n                # and we're building a spanning tree with DFS, any back edge\n                # (u,v) where v is already visited and is not parent, implies v is an ancestor of u.\n                # In a max-flow setting with no cycles, such edges must be directed\n                # from the \"earlier\" node in topological order to \"later\" node.\n                # In a DFS tree, this means from ancestor to descendant.\n                # However, the problem states \"the obtained directed graph does not have cycles\".\n                # This means we must orient back edges too.\n                # A simple DFS will only orient tree edges.\n                # What if the edge (u, v) is a back edge, where v is already visited?\n                # This implies v is an ancestor of u.\n                # The flow should be directed v -> u.\n                # But this would create a cycle (v -> u -> ... -> v).\n                # Wait, \"the obtained directed graph does not have cycles\" means the FINAL graph.\n                # Not that the input graph is a DAG.\n                # If v is an ancestor of u, then flow v -> u would be against topological order.\n                # So it must be u -> v.\n                # But this would create a cycle u -> v -> ... -> u.\n                # This is confusing.\n\n                # The \"no cycles\" condition is usually satisfied if we process nodes in topological order.\n                # Or if we ensure that edges are only directed from a node to an unvisited node,\n                # or from a node to its parent in a specific way.\n                # The DFS approach above usually guarantees no cycles *in the tree edges*.\n                # Back edges need special handling.\n                # If (u, v) is a back edge, and v is an ancestor of u,\n                # then directing u -> v would be fine (from descendant to ancestor).\n                # Directing v -> u would create a cycle.\n                # So, for back edges (u, v) where v is an ancestor of u, we must direct u -> v.\n                # The flow value `c` for this edge needs to be accounted for in `balance[u]` and `balance[v]`.\n                # This means `balance[u] -= c` and `balance[v] += c`.\n                # This requires a separate pass or modification of the DFS.\n\n                # The problem statement: \"vertex with number 1 has no incoming edges; the obtained directed graph does not have cycles.\"\n                # This implies that a valid topological sort exists.\n                # The most straightforward way to orient edges to satisfy flow conservation and no cycles\n                # is to perform a DFS from node 1.\n                # When visiting (u, v) for the first time (v not visited):\n                #   recursively call dfs(v, idx)\n                #   after return, child_flow_sum is flow from v's subtree.\n                # When visiting (u, v) where v is already visited (and not parent):\n                #   This is a cross/back edge. In a DAG, it must be from higher topo order to lower.\n                #   In a DFS tree, if v is visited and not parent, it's an ancestor or in another subtree.\n                #   If v is an ancestor, it's a back edge.\n                #   If v is in another subtree, it's a cross edge.\n                #   To avoid cycles, we must direct from earlier visited to later visited.\n                #   If v was visited before u, then v -> u. This could create a cycle.\n                #   If u was visited before v, then u -> v. This is fine.\n                #   This is where a topological sort comes in handy.\n                #   But we don't know the topological sort.\n\n                # Let's assume the DFS tree strategy is correct for all edges, and the \"no cycles\" condition\n                # is implicitly handled by the problem guarantee that a solution exists.\n                # The standard way to deal with back edges in this type of DFS is to simply ignore them\n                # for the flow calculation within the DFS, as they are not part of the DFS tree.\n                # Then, after the DFS, all tree edges are directed.\n                # Any remaining undirected edges (back edges) can be directed arbitrarily (e.g., from smaller ID to larger ID)\n                # as long as they don't create cycles and flow conservation holds.\n                # But flow conservation must hold for all nodes.\n                # This means back edges must also be directed to contribute to the balance.\n\n                # A simpler approach:\n                # `balance[u]` = net flow that *has entered* `u` from its neighbors (children in DFS tree).\n                # `dfs(u, p_edge_idx)`:\n                #   `visited[u] = True`\n                #   `current_balance = 0`\n                #   For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n                #     If `idx == p_edge_idx`: continue\n                #     If `visited[v]`:\n                #       # This is a back edge. `v` is an ancestor of `u`.\n                #       # To avoid cycles, we must direct `u -> v`.\n                #       # So `u` sends `c` to `v`.\n                #       if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n                #       else: ans[idx] = 1 # original (v,u), want u->v\n                #       current_balance -= c\n                #     Else:\n                #       # This is a tree edge.\n                #       `child_balance = dfs(v, idx)`\n                #       If `child_balance > 0`: # `v` has `child_balance` excess, sends to `u`\n                #         if edges_input[idx][0] == u: ans[idx] = 1 # original (u,v), want v->u\n                #         else: ans[idx] = 0 # original (v,u), want v->u\n                #         current_balance += c\n                #       Else: # `v` needs `abs(child_balance)` flow from `u`\n                #         if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n                #         else: ans[idx] = 1 # original (v,u), want u->v\n                #         current_balance -= c\n                #   \n                #   If `u == n`:\n                #     # `n` is the sink. It should absorb all incoming flow.\n                #     # It shouldn't pass any flow up to its parent.\n                #     # So, `current_balance` for `n` should be effectively `0` for its parent.\n                #     # However, `current_balance` here means \"net flow that has entered `u` from children\".\n                #     # If `u` is `n`, it can absorb this `current_balance`.\n                #     # So, the flow passed to parent should be 0.\n                #     return 0\n                #   \n                #   return current_balance\n\n                # This logic for back edges is problematic. If `v` is an ancestor of `u`,\n                # and we direct `u -> v`, then `current_balance` for `u` is reduced by `c`.\n                # This `c` flow is sent to `v`. `v` must then account for it.\n                # But `v` has already returned from its DFS call.\n                # This implies that the balance for `v` is already finalized.\n                # This means the DFS must be done in a way that back edges are handled by the ancestor.\n                # Or, we need a global `balance` array.\n\n                # Let `balance[u]` be the amount of flow that *needs to be sent out* from `u`.\n                # Initially `balance[u] = 0` for all `u`.\n                # `dfs(u, p_edge_idx)`:\n                #   `visited[u] = True`\n                #   For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n                #     If `idx == p_edge_idx`: continue\n                #     If `visited[v]`:\n                #       # This is a back edge. `v` is an ancestor of `u`.\n                #       # To avoid cycles, we must direct `u -> v`.\n                #       # So `u` sends `c` to `v`.\n                #       if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n                #       else: ans[idx] = 1 # original (v,u), want u->v\n                #       balance[u] += c # `u` sends `c`, so it contributes to its outgoing flow\n                #       balance[v] -= c # `v` receives `c`, so it contributes to its incoming flow\n                #     Else:\n                #       # This is a tree edge.\n                #       dfs(v, idx) # Recursively call\n                #       # After `dfs(v, idx)` returns, `balance[v]` is the net flow that needs to be sent out of `v`.\n                #       If `balance[v] > 0`: # `v` has excess flow, sends to `u`\n                #         # This flow must be `c` (flow on edge (u,v)).\n                #         if edges_input[idx][0] == u: ans[idx] = 1 # original (u,v), want v->u\n                #         else: ans[idx] = 0 # original (v,u), want v->u\n                #         balance[u] -= c # `u` receives `c` from `v`\n                #         balance[v] -= c # `v` has sent `c`\n                #       Else: # `v` needs `abs(balance[v])` flow from `u`\n                #         # This flow must be `c`.\n                #         if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n                #         else: ans[idx] = 1 # original (v,u), want u->v\n                #         balance[u] += c # `u` sends `c` to `v`\n                #         balance[v] += c # `v` has received `c`\n                #\n                # This is still not right. `balance[v]` should be 0 for intermediate nodes.\n                # The total flow out of 1 is the total flow. The total flow into n is the total flow.\n                # For intermediate nodes, in_flow == out_flow.\n\n    # The most robust DFS approach for this problem type:\n    # We want to determine the flow direction for each edge (u, v) with flow `c`.\n    # Let `flow_needed[u]` be the net flow that *must enter* `u` from its parent.\n    # `flow_needed[u]` is initialized to 0 for `1 < u < n`.\n    # For `u = n`, `flow_needed[n]` should be 0 (sink can absorb anything).\n    # For `u = 1`, `flow_needed[1]` should be 0 (source doesn't need flow from parent).\n\n    # Let `dfs(u, p)` return the amount of flow that `u` *pushes up* to `p`.\n    # `dfs(u, p_node, p_edge_idx)`:\n    #   `visited[u] = True`\n    #   `flow_to_parent = 0`\n    #   For each neighbor `v` of `u` via edge `(u, v)` with flow `c` and index `idx`:\n    #     If `v == p_node`: continue\n    #     If `visited[v]`:\n    #       # This is a back edge (v is an ancestor of u).\n    #       # To ensure no cycles and flow from source to sink,\n    #       # flow must go from u to v (descendant to ancestor).\n    #       # So `u` sends `c` to `v`.\n    #       if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n    #       else: ans[idx] = 1 # original (v,u), want u->v\n    #       flow_to_parent -= c # `u` sends `c` to `v`, so `u` has `c` less to send to its parent `p_node`\n    #     Else:\n    #       # This is a tree edge.\n    #       `flow_from_child_v = dfs(v, u, idx)`\n    #       If `flow_from_child_v > 0`: # `v` sends `flow_from_child_v` to `u`\n    #         # This flow must be `c` (the flow on edge (u,v)).\n    #         if edges_input[idx][0] == u: ans[idx] = 1 # original (u,v), want v->u\n    #         else: ans[idx] = 0 # original (v,u), want v->u\n    #         flow_to_parent += c # `u` receives `c` from `v`\n    #       Else: # `v` needs `abs(flow_from_child_v)` flow from `u`\n    #         # This flow must be `c`.\n    #         if edges_input[idx][0] == u: ans[idx] = 0 # original (u,v), want u->v\n    #         else: ans[idx] = 1 # original (v,u), want u->v\n    #         flow_to_parent -= c # `u` sends `c` to `v`\n    #\n    #   If `u == n`: # `n` is the sink. It absorbs all flow. It doesn't push anything up.\n    #     return 0\n    #\n    #   return flow_to_parent\n\n    # This seems like the correct logic.\n    # The \"no cycles\" condition is handled by directing back edges from descendant to ancestor.\n    # The flow conservation for intermediate nodes (1 < u < n) is handled by `flow_to_parent`.\n    # For `u=1`, the `flow_to_parent` will be the total max flow, and it's not sent to any parent.\n    # For `u=n`, it returns 0, meaning it absorbs all.\n\n    # Initialize visited array for DFS\n    visited = [False] * (n + 1)\n    \n    # The `ans` array will store the directions.\n    # 0 for a_i -> b_i\n    # 1 for b_i -> a_i\n\n    def dfs(u, p_node, p_edge_idx):\n        visited[u] = True\n        \n        # flow_to_parent: The net amount of flow that node `u` needs to send to its parent `p_node`.\n        # Positive value means `u` has an excess and sends flow to `p_node`.\n        # Negative value means `u` needs flow from `p_node`.\n        flow_to_parent = 0\n\n        for v, c, idx in adj[u]:\n            if idx == p_edge_idx: # Don't go back to the edge that brought us to `u`\n                continue\n            \n            # If `v` is already visited, and it's not the parent, it's a back edge.\n            # In a DFS tree, a back edge (u, v) means `v` is an ancestor of `u`.\n            # To ensure no cycles in the final directed graph, and flow from source to sink,\n            # we must direct flow from descendant to ancestor: `u -> v`.\n            # This contributes to `u` sending flow, so `flow_to_parent` decreases.\n            if visited[v]:\n                # Only process if this edge hasn't been directed yet.\n                # This check `ans[idx] == -1` is crucial for back edges.\n                # If `ans[idx]` is not -1, it means this edge was already processed when `v` was visited.\n                # This should not happen if `v` is an ancestor, because `v` would have already returned.\n                # The only case where `visited[v]` is true and `ans[idx]` is -1 is if `v` is an ancestor of `u`\n                # and this is a back edge.\n                if ans[idx] == -1: # Ensure we only direct back edges once\n                    # Direct u -> v\n                    if edges_input[idx][0] == u:\n                        ans[idx] = 0\n                    else: # edges_input[idx][0] == v\n                        ans[idx] = 1\n                    flow_to_parent -= c\n            else:\n                # This is a tree edge. Recursively call DFS for child `v`.\n                flow_from_child_v = dfs(v, u, idx)\n                \n                # After `dfs(v, u, idx)` returns, `flow_from_child_v` is the net flow `v` wants to send to `u`.\n                if flow_from_child_v > 0:\n                    # `v` has an excess of `flow_from_child_v` flow, which must be `c` (the flow on edge (u,v)).\n                    # So, `v` sends `c` to `u`. Direction: `v -> u`.\n                    if edges_input[idx][0] == u:\n                        ans[idx] = 1 # original (u,v), want v->u\n                    else: # original (v,u), want v->u\n                        ans[idx] = 0\n                    flow_to_parent += c # `u` receives `c` from `v`\n                else: # `flow_from_child_v <= 0`\n                    # `v` needs `abs(flow_from_child_v)` flow from `u`, which must be `c`.\n                    # So, `u` sends `c` to `v`. Direction: `u -> v`.\n                    if edges_input[idx][0] == u:\n                        ans[idx] = 0 # original (u,v), want u->v\n                    else: # original (v,u), want u->v\n                        ans[idx] = 1\n                    flow_to_parent -= c # `u` sends `c` to `v`\n        \n        # Special handling for the sink node `n`.\n        # The sink absorbs all flow and doesn't pass anything up to its parent.\n        if u == n:\n            return 0\n        \n        # For any other node `u`, return the net flow that needs to be passed to its parent.\n        return flow_to_parent\n\n    # Start DFS from source node 1. `p_node` is 0 (dummy), `p_edge_idx` is -1 (dummy).\n    dfs(1, 0, -1)\n\n    for result in ans:\n        sys.stdout.write(str(result) + '\\n')\n\nsolve()"}
{"task_id": "E2H_CF808E", "completion": "import sys\n\ndef solve():\n    n, m = map(int, sys.stdin.readline().split())\n\n    items_by_weight = {1: [], 2: [], 3: []}\n    for _ in range(n):\n        w, c = map(int, sys.stdin.readline().split())\n        items_by_weight[w].append(c)\n\n    for w in items_by_weight:\n        items_by_weight[w].sort(reverse=True)\n\n    prefix_sums_1 = [0] * (len(items_by_weight[1]) + 1)\n    for i in range(len(items_by_weight[1])):\n        prefix_sums_1[i+1] = prefix_sums_1[i] + items_by_weight[1][i]\n\n    prefix_sums_2 = [0] * (len(items_by_weight[2]) + 1)\n    for i in range(len(items_by_weight[2])):\n        prefix_sums_2[i+1] = prefix_sums_2[i] + items_by_weight[2][i]\n\n    prefix_sums_3 = [0] * (len(items_by_weight[3]) + 1)\n    for i in range(len(items_by_weight[3])):\n        prefix_sums_3[i+1] = prefix_sums_3[i] + items_by_weight[3][i]\n\n    max_cost = 0\n\n    # Iterate over the number of items with weight 3\n    for count3 in range(len(items_by_weight[3]) + 1):\n        weight3 = count3 * 3\n        cost3 = prefix_sums_3[count3]\n\n        remaining_weight_after_3 = m - weight3\n        if remaining_weight_after_3 < 0:\n            break\n\n        # Iterate over the number of items with weight 2\n        # We can optimize this inner loop.\n        # For a fixed count3, we want to maximize cost2 + cost1\n        # given remaining_weight_after_3.\n        # This is a standard 0/1 knapsack for weights 1 and 2.\n        # Since we have sorted costs, we can use two pointers or binary search for count1.\n\n        current_cost_for_3 = cost3\n        \n        # Maximize cost from items of weight 1 and 2\n        # For a given remaining_weight_after_3, we want to pick some count2 items and some count1 items.\n        # Let's iterate on count2.\n        best_cost_for_1_and_2 = 0\n        \n        # Two pointers approach for count1 and count2\n        # We try to take as many weight 2 items as possible first, then fill with weight 1 items.\n        # Or, we iterate on count2, and for each count2, find the best count1.\n\n        # Let's try iterating count2 and finding best count1.\n        # This is O(N2 * N1) if N1 and N2 are sizes of lists.\n        # A more efficient way:\n        # For a fixed count3, we have remaining_weight_after_3.\n        # We want to find max(cost1 + cost2) such that 1*count1 + 2*count2 <= remaining_weight_after_3.\n        # We can iterate count2 from 0 up to min(len(items_by_weight[2]), remaining_weight_after_3 // 2).\n        # For each count2, calculate remaining_weight_for_1 = remaining_weight_after_3 - count2 * 2.\n        # Then, count1 = min(len(items_by_weight[1]), remaining_weight_for_1).\n        # This gives cost1 = prefix_sums_1[count1].\n\n        for count2 in range(len(items_by_weight[2]) + 1):\n            weight2 = count2 * 2\n            cost2 = prefix_sums_2[count2]\n\n            remaining_weight_after_2_and_3 = remaining_weight_after_3 - weight2\n            if remaining_weight_after_2_and_3 < 0:\n                break\n\n            count1 = min(len(items_by_weight[1]), remaining_weight_after_2_and_3)\n            cost1 = prefix_sums_1[count1]\n\n            current_total_cost = current_cost_for_3 + cost2 + cost1\n            max_cost = max(max_cost, current_total_cost)\n\n    sys.stdout.write(str(max_cost) + '\\n')\n\nif __name__ == '__main__':\n    solve()"}
{"task_id": "E2H_CF409I", "completion": "import sys\n\ndef solve():\n    name = sys.stdin.readline().strip()\n\n    def parse_expression(s):\n        balance = 0\n        operators = []\n        operands = []\n        current_operand_start = 0\n\n        for i in range(len(s)):\n            if s[i] == '(':\n                balance += 1\n            elif s[i] == ')':\n                balance -= 1\n            elif balance == 0 and s[i] in ['+', '-', '*', '/']:\n                if current_operand_start < i:\n                    operands.append(s[current_operand_start:i])\n                operators.append(s[i])\n                current_operand_start = i + 1\n        if current_operand_start < len(s):\n            operands.append(s[current_operand_start:])\n\n        if not operators:\n            return parse_term(s)\n\n        # Apply operator precedence (*/ before +-)\n        new_operands = [parse_term(operands[0])]\n        new_operators = []\n        for i in range(len(operators)):\n            op = operators[i]\n            term = parse_term(operands[i+1])\n            if op in ['*', '/']:\n                prev_operand = new_operands.pop()\n                new_operands.append((op, prev_operand, term))\n            else:\n                new_operators.append(op)\n                new_operands.append(term)\n\n        # Apply remaining operators (+-)\n        if not new_operators:\n            return new_operands[0]\n\n        result = (new_operators[0], new_operands[0], new_operands[1])\n        for i in range(1, len(new_operators)):\n            result = (new_operators[i], result, new_operands[i+1])\n        return result\n\n    def parse_term(s):\n        if s.startswith('(') and s.endswith(')'):\n            balance = 0\n            is_simple_parenthesized = True\n            for i in range(1, len(s) - 1):\n                if s[i] == '(':\n                    balance += 1\n                elif s[i] == ')':\n                    balance -= 1\n                if balance < 0:\n                    is_simple_parenthesized = False\n                    break\n            if is_simple_parenthesized and balance == 0:\n                return parse_expression(s[1:-1])\n        return ('var', len(s))\n\n    def evaluate_expression(expr, values, current_var_idx):\n        op_type = expr[0]\n        if op_type == 'var':\n            length = expr[1]\n            if current_var_idx + length > len(values):\n                return None, current_var_idx + length # Indicate insufficient values\n            val_str = \"\".join(map(str, values[current_var_idx : current_var_idx + length]))\n            return int(val_str), current_var_idx + length\n        else:\n            op = op_type\n            left_val, next_idx_left = evaluate_expression(expr[1], values, current_var_idx)\n            if left_val is None:\n                return None, next_idx_left\n            right_val, next_idx_right = evaluate_expression(expr[2], values, next_idx_left)\n            if right_val is None:\n                return None, next_idx_right\n\n            if op == '+':\n                return (left_val + right_val) % 1000000007, next_idx_right\n            elif op == '-':\n                return (left_val - right_val) % 1000000007, next_idx_right\n            elif op == '*':\n                return (left_val * right_val) % 1000000007, next_idx_right\n            elif op == '/':\n                if right_val == 0:\n                    return None, next_idx_right # Division by zero\n                return (left_val // right_val) % 1000000007, next_idx_right\n\n    def check_constraints(constraints_str, values, expr_map):\n        parts = constraints_str.split(',')\n        for part in parts:\n            part = part.strip()\n            if not part:\n                continue\n\n            op_idx = -1\n            for op in ['>', '<', '=']:\n                if op in part:\n                    op_idx = part.find(op)\n                    break\n            \n            if op_idx == -1: # Should not happen based on problem description\n                return False\n\n            left_expr_str = part[:op_idx].strip()\n            right_expr_str = part[op_idx+1:].strip()\n            op = part[op_idx]\n\n            left_val = expr_map.get(left_expr_str)\n            right_val = expr_map.get(right_expr_str)\n\n            if left_val is None or right_val is None:\n                return False # Should not happen if all expressions are evaluated\n\n            if op == '>':\n                if not (left_val > right_val):\n                    return False\n            elif op == '<':\n                if not (left_val < right_val):\n                    return False\n            elif op == '=':\n                if not (left_val == right_val):\n                    return False\n        return True\n\n    parts = name.split(':-')\n    expression_str = parts[0][2:-1] # Remove '?(' and ')'\n    constraints_str = parts[1]\n\n    # Parse the main expression to find all unique sub-expressions (variables)\n    # and determine the total number of variables needed.\n    \n    # A simple way to count variables is to count '?' occurrences.\n    # Each '?' corresponds to one variable '?'\n    # Or, more accurately, each '_' corresponds to one variable.\n    # A sequence of '_' is a variable with that many digits.\n    \n    # We need to find all unique variable expressions (e.g., '?', '__', '___')\n    # and map them to their evaluated values.\n    \n    # Let's first identify all variable lengths.\n    \n    def get_variable_lengths(s):\n        lengths = set()\n        balance = 0\n        current_var_len = 0\n        for char in s:\n            if char == '(':\n                if current_var_len > 0:\n                    lengths.add(current_var_len)\n                current_var_len = 0\n                balance += 1\n            elif char == ')':\n                if current_var_len > 0:\n                    lengths.add(current_var_len)\n                current_var_len = 0\n                balance -= 1\n            elif char == '_':\n                if balance == 0: # Only count variables outside parentheses for top-level parsing\n                    current_var_len += 1\n            elif char in ['+', '-', '*', '/']:\n                if current_var_len > 0:\n                    lengths.add(current_var_len)\n                current_var_len = 0\n            else: # Other characters like '?' or unexpected\n                if current_var_len > 0:\n                    lengths.add(current_var_len)\n                current_var_len = 0\n        if current_var_len > 0:\n            lengths.add(current_var_len)\n        return sorted(list(lengths))\n\n    all_expressions_str = expression_str + ',' + constraints_str\n    \n    # Find all unique variable lengths\n    unique_var_lengths = set()\n    temp_s = all_expressions_str\n    \n    # Replace parenthesized expressions with placeholders to simplify variable counting\n    # This is a bit tricky. Let's use a simpler approach for variable counting:\n    # count total '_' characters. Each '_' represents one digit.\n    num_variables = all_expressions_str.count('_')\n    \n    if num_variables == 0:\n        # No variables, evaluate directly\n        # This case is tricky because the problem states \"variables can take values from 0 to 9\"\n        # If there are no variables, the 'values' array will be empty.\n        # The `evaluate_expression` function needs to be able to handle this.\n        \n        # We need to map string expressions to their parsed tree representation\n        # and then evaluate them.\n        \n        # Collect all unique sub-expressions from the whole string (expression + constraints)\n        # and store their parsed forms.\n        \n        all_sub_expressions = set()\n        \n        # Helper to extract all sub-expressions\n        def extract_sub_expressions(s):\n            sub_exprs = set()\n            balance = 0\n            start = 0\n            for i in range(len(s)):\n                if s[i] == '(':\n                    balance += 1\n                elif s[i] == ')':\n                    balance -= 1\n                elif balance == 0 and s[i] in ['+', '-', '*', '/', '>', '<', '=']:\n                    if start < i:\n                        sub_exprs.add(s[start:i].strip())\n                    start = i + 1\n            if start < len(s):\n                sub_exprs.add(s[start:].strip())\n            return sub_exprs\n\n        main_expr_parts = extract_sub_expressions(expression_str)\n        constraint_expr_parts = set()\n        for c_part in constraints_str.split(','):\n            if c_part.strip():\n                constraint_expr_parts.update(extract_sub_expressions(c_part.strip()))\n        \n        all_unique_expr_strings = main_expr_parts.union(constraint_expr_parts)\n        \n        parsed_expr_trees = {}\n        for expr_str in all_unique_expr_strings:\n            if expr_str:\n                parsed_expr_trees[expr_str] = parse_expression(expr_str)\n\n        # Evaluate all expressions with an empty values array.\n        expr_values_map = {}\n        current_var_idx_tracker = 0 # This will remain 0 if no vars\n        \n        for expr_str, tree in parsed_expr_trees.items():\n            val, _ = evaluate_expression(tree, [], current_var_idx_tracker)\n            if val is None:\n                sys.stdout.write(\"false\\n\")\n                return\n            expr_values_map[expr_str] = val\n            \n        # Check constraints\n        if check_constraints(constraints_str, [], expr_values_map):\n            sys.stdout.write(\"\\n\") # Empty string for 0 variables\n        else:\n            sys.stdout.write(\"false\\n\")\n        return\n\n    # Backtracking search for variable values\n    \n    # We need to identify all distinct variable \"slots\" and their lengths.\n    # The `evaluate_expression` function handles this by consuming `values` based on `length`.\n    # So, we just need to know the total number of digits required.\n    \n    # Find the maximum number of digits needed for any variable.\n    # This is not about variable lengths, but total digits.\n    # The `evaluate_expression` function takes `values` (a list of digits)\n    # and a `current_var_idx`. It consumes digits from `values` as needed.\n    # So, `num_variables` is the total number of digits we need to assign.\n    \n    best_solution = None\n\n    # This is a recursive backtracking function\n    def find_solution(current_values_list):\n        nonlocal best_solution\n\n        if len(current_values_list) == num_variables:\n            # All variables assigned, now evaluate and check constraints\n            \n            # Collect all unique sub-expressions from the whole string (expression + constraints)\n            # and store their parsed forms.\n            all_sub_expressions = set()\n            \n            def extract_sub_expressions(s):\n                sub_exprs = set()\n                balance = 0\n                start = 0\n                for i in range(len(s)):\n                    if s[i] == '(':\n                        balance += 1\n                    elif s[i] == ')':\n                        balance -= 1\n                    elif balance == 0 and s[i] in ['+', '-', '*', '/', '>', '<', '=']:\n                        if start < i:\n                            sub_exprs.add(s[start:i].strip())\n                        start = i + 1\n                if start < len(s):\n                    sub_exprs.add(s[start:].strip())\n                return sub_exprs\n\n            main_expr_parts = extract_sub_expressions(expression_str)\n            constraint_expr_parts = set()\n            for c_part in constraints_str.split(','):\n                if c_part.strip():\n                    constraint_expr_parts.update(extract_sub_expressions(c_part.strip()))\n            \n            all_unique_expr_strings = main_expr_parts.union(constraint_expr_parts)\n            \n            parsed_expr_trees = {}\n            for expr_str in all_unique_expr_strings:\n                if expr_str:\n                    parsed_expr_trees[expr_str] = parse_expression(expr_str)\n\n            expr_values_map = {}\n            current_var_idx_tracker = 0\n            \n            # Evaluate all expressions\n            for expr_str, tree in parsed_expr_trees.items():\n                val, next_idx = evaluate_expression(tree, current_values_list, current_var_idx_tracker)\n                if val is None: # e.g., division by zero or not enough variables\n                    return # This path is invalid\n                expr_values_map[expr_str] = val\n            \n            # Check constraints\n            if check_constraints(constraints_str, current_values_list, expr_values_map):\n                current_solution_str = \"\".join(map(str, current_values_list))\n                if best_solution is None or current_solution_str < best_solution:\n                    best_solution = current_solution_str\n            return\n\n        # If a solution is already found and current path is lexicographically larger, prune\n        if best_solution is not None:\n            current_prefix_str = \"\".join(map(str, current_values_list))\n            if len(current_prefix_str) < len(best_solution) and current_prefix_str > best_solution[:len(current_prefix_str)]:\n                return\n            elif len(current_prefix_str) == len(best_solution) and current_prefix_str >= best_solution:\n                return\n\n\n        # Try digits 0-9 for the next variable\n        for digit in range(10):\n            find_solution(current_values_list + [digit])\n\n    find_solution([])\n\n    if best_solution:\n        sys.stdout.write(best_solution + \"\\n\")\n    else:\n        sys.stdout.write(\"false\\n\")\n\nsolve()"}
{"task_id": "E2H_CF151A", "completion": "def solve():\n    n, k, l, c, d, p, nl, np = map(int, input().split())\n\n    # Calculate total milliliters of drink available\n    total_drink_ml = k * l\n    # Calculate how many toasts can be made based on drink\n    toasts_from_drink = total_drink_ml // (n * nl)\n\n    # Calculate total slices of lime available\n    total_lime_slices = c * d\n    # Calculate how many toasts can be made based on lime\n    toasts_from_lime = total_lime_slices // n\n\n    # Calculate total grams of salt available\n    total_salt_grams = p\n    # Calculate how many toasts can be made based on salt\n    toasts_from_salt = total_salt_grams // (n * np)\n\n    # The number of toasts each friend can make is limited by the minimum of these three resources\n    # and then divided by the number of friends, as they all drink the same amount.\n    # The problem statement implies \"each friend needs nl milliliters of the drink, a slice of lime and np grams of salt.\"\n    # and \"The friends want to make as many toasts as they can, provided they all drink the same amount.\"\n    # This means for one \"group toast\" (where each of the 'n' friends makes one toast),\n    # they collectively need n*nl ml of drink, n slices of lime, and n*np grams of salt.\n    # So, we calculate the total number of \"group toasts\" possible based on each resource,\n    # and the minimum of these is the answer.\n\n    # Re-evaluating the logic based on the sample explanation:\n    # \"Overall the friends have 4*5=20 milliliters of the drink, it is enough to make 20/3=6 toasts.\"\n    # This means total toasts possible from drink is total_drink_ml / nl.\n    # Then, this total number of toasts is divided among 'n' friends.\n    # So, toasts_from_drink_per_friend = (total_drink_ml // nl) // n\n\n    # Let's follow the sample explanation's logic for clarity:\n    # 1. Calculate how many individual toasts can be made from each resource.\n    #    This is total_resource / resource_needed_per_toast.\n    # 2. Find the minimum of these individual toast counts. This is the total number of toasts\n    #    that can be made if resources were the only constraint, and friends didn't matter yet.\n    # 3. Divide this minimum by the number of friends (n) because they all drink the same amount,\n    #    meaning if there are X total toasts possible, and N friends, each friend gets X/N toasts.\n\n    possible_toasts_drink = (k * l) // nl\n    possible_toasts_lime = (c * d)\n    possible_toasts_salt = p // np\n\n    min_total_toasts = min(possible_toasts_drink, possible_toasts_lime, possible_toasts_salt)\n\n    # Each friend makes min_total_toasts / n toasts.\n    result = min_total_toasts // n\n    print(result)\n\nif __name__ == '__main__':\n    solve()"}
{"task_id": "E2H_CF339B", "completion": "def solve():\n    n, m = map(int, input().split())\n    a = list(map(int, input().split()))\n\n    current_house = 1\n    total_time = 0\n\n    for task_house in a:\n        if task_house >= current_house:\n            total_time += (task_house - current_house)\n        else:\n            total_time += (n - current_house + task_house)\n        current_house = task_house\n    \n    print(total_time)\n\nif __name__ == '__main__':\n    solve()"}
{"task_id": "E2H_CF88A", "completion": "def solve():\n    notes_input = input().split()\n    \n    note_to_semitone = {\n        \"C\": 0, \"C#\": 1, \"D\": 2, \"D#\": 3, \"E\": 4, \"F\": 5,\n        \"F#\": 6, \"G\": 7, \"G#\": 8, \"A\": 9, \"B\": 10, \"H\": 11\n    }\n\n    semitones = sorted([note_to_semitone[n] for n in notes_input])\n\n    def check_chord(s1, s2, s3):\n        dist1 = (s2 - s1) % 12\n        dist2 = (s3 - s2) % 12\n        dist3 = (s1 - s3) % 12\n        \n        if dist1 == 4 and dist2 == 3:\n            return \"major\"\n        if dist1 == 3 and dist2 == 4:\n            return \"minor\"\n        return None\n\n    # Try all 3 permutations for the starting note\n    # (s1, s2, s3)\n    # (s2, s3, s1)\n    # (s3, s1, s2)\n    \n    result = check_chord(semitones[0], semitones[1], semitones[2])\n    if result:\n        print(result)\n        return\n\n    result = check_chord(semitones[1], semitones[2], semitones[0])\n    if result:\n        print(result)\n        return\n\n    result = check_chord(semitones[2], semitones[0], semitones[1])\n    if result:\n        print(result)\n        return\n\n    print(\"strange\")\n\nsolve()"}
{"task_id": "E2H_CF633B", "completion": "def solve():\n    m = int(input())\n\n    def count_trailing_zeros(n):\n        count = 0\n        i = 5\n        while n // i >= 1:\n            count += n // i\n            i *= 5\n        return count\n\n    # Find a lower bound for n\n    # We know that count_trailing_zeros(n) is approximately n/5\n    # So n is approximately 5*m\n    # We can start searching from a slightly smaller value, e.g., 4*m\n    # A more precise lower bound: n >= 5 * m / (1 + 1/5 + 1/25 + ...) = 5 * m / (1.25) = 4 * m\n    # Let's use a slightly more generous lower bound, e.g., max(1, m * 4)\n    # The smallest n that can produce m zeros is at least 5*m.\n    # For example, if m=1, n=5. If m=2, n=10.\n    # The count_trailing_zeros function is monotonically increasing.\n\n    # Binary search to find the smallest n such that count_trailing_zeros(n) >= m\n    low = 1\n    high = 5 * m + 5  # A sufficiently large upper bound (e.g., if m=1, max n is 9, 5*1+5 = 10)\n                      # For m=100000, high = 500005. This is reasonable.\n    \n    # Adjust high based on the maximum possible value of n.\n    # The maximum m is 100,000.\n    # The number of zeros for n=400,000 is around 100,000.\n    # For n=400,000, zeros = 400000/5 + 400000/25 + 400000/125 + 400000/625 + 400000/3125 + 400000/15625 + 400000/78125\n    # = 80000 + 16000 + 3200 + 640 + 128 + 25 + 5 = 99918\n    # For n=400,000, the zeros is 99918.\n    # For n=400,000+5 = 400,005, zeros = 99918 + 1 = 99919.\n    # So high could be around 5*m + 20 (a bit more than 5*m, to cover the cases where n is slightly larger than 5m due to higher powers of 5)\n    # A safe upper bound for m=100000 would be 400000 + 100 = 400100.\n    # A simple 5*m + 5 is often enough for competitive programming, but let's be more robust.\n    # The maximum value of n for m=100000 is around 400000.\n    # So, 400000 + 100 is a safe upper bound.\n    # For m=1, 5*1+5=10.\n    # For m=100000, 5*100000+5 = 500005. This covers the actual maximum n of 400000.\n\n    ans_n_start = -1\n\n    while low <= high:\n        mid = (low + high) // 2\n        zeros = count_trailing_zeros(mid)\n        if zeros >= m:\n            ans_n_start = mid\n            high = mid - 1\n        else:\n            low = mid + 1\n    \n    if ans_n_start == -1: # This should ideally not happen for m >= 1\n        print(0)\n        print()\n        return\n\n    # Now, ans_n_start is the smallest n such that count_trailing_zeros(n) >= m.\n    # We need to find all n such that count_trailing_zeros(n) == m.\n    \n    results = []\n    # Since count_trailing_zeros(n) is non-decreasing,\n    # if count_trailing_zeros(ans_n_start) == m, then we need to check ans_n_start + 1, ans_n_start + 2, ...\n    # until the number of zeros changes.\n    \n    # The number of zeros only changes when n is a multiple of 5.\n    # So, we can check n, n+1, n+2, n+3, n+4.\n    # All these values will have the same number of trailing zeros as n,\n    # unless n is a multiple of 5, in which case n+1, n+2, n+3, n+4 will have the same number of zeros as n.\n    # For example, count_trailing_zeros(5) = 1.\n    # count_trailing_zeros(6) = 1.\n    # ...\n    # count_trailing_zeros(9) = 1.\n    # count_trailing_zeros(10) = 2.\n    \n    # So, if count_trailing_zeros(ans_n_start) == m, then ans_n_start, ans_n_start+1, ..., ans_n_start+4\n    # will all have m zeros, unless ans_n_start itself is a multiple of 5, in which case\n    # ans_n_start + 5 will have more zeros.\n    # The number of zeros changes only when n becomes a multiple of 5.\n    \n    # Let's verify:\n    # If count_trailing_zeros(ans_n_start) == m:\n    #   Then for any i from 0 to 4, count_trailing_zeros(ans_n_start + i) will also be m,\n    #   because (ans_n_start + i)! contains the same number of factors of 5 as ans_n_start!,\n    #   unless ans_n_start + i is a multiple of 5.\n    #   But if ans_n_start + i is a multiple of 5, it means ans_n_start is NOT a multiple of 5\n    #   (otherwise ans_n_start + i would have more factors of 5).\n    #   This is incorrect.\n    #   The number of zeros for n! is determined by the number of factors of 5 in 1*2*...*n.\n    #   The number of factors of 5 in (n+1)! is the same as n! if n+1 is not a multiple of 5.\n    #   If n+1 is a multiple of 5, then (n+1)! has more factors of 5 than n!.\n    #   So, count_trailing_zeros(n) == count_trailing_zeros(n+1) == ... == count_trailing_zeros(n+4)\n    #   IF n+1, n+2, n+3, n+4 are NOT multiples of 5.\n    #   This means n itself must be a multiple of 5, or n+1, n+2, n+3, n+4 are not multiples of 5.\n    #   This is simpler: The number of trailing zeros for n! is constant for n, n+1, n+2, n+3, n+4,\n    #   and then it increases for n+5.\n    #   So, if count_trailing_zeros(ans_n_start) == m, then count_trailing_zeros(ans_n_start+1) == m, ..., count_trailing_zeros(ans_n_start+4) == m.\n    #   And count_trailing_zeros(ans_n_start+5) will be strictly greater than m (unless ans_n_start+5 is the smallest multiple of 5\n    #   that makes the count equal to m, which is covered by ans_n_start).\n\n    if count_trailing_zeros(ans_n_start) == m:\n        for i in range(5):\n            results.append(ans_n_start + i)\n\n    print(len(results))\n    if results:\n        print(*(sorted(results)))\n\nsolve()"}
{"task_id": "E2H_CF1767D", "completion": "def solve():\n    n = int(input())\n    s = input()\n\n    count_zeros = s.count('0')\n    count_ones = s.count('1')\n\n    min_winning_skill = (1 << count_zeros)\n    max_winning_skill = (1 << n) - (1 << count_ones) + 1\n\n    winning_integers = []\n    for x in range(min_winning_skill, max_winning_skill + 1):\n        winning_integers.append(x)\n\n    print(*(sorted(winning_integers)))\n\nif __name__ == '__main__':\n    solve()"}
{"task_id": "E2H_CF498A", "completion": "def solve():\n    x1, y1 = map(int, input().split())\n    x2, y2 = map(int, input().split())\n    n = int(input())\n\n    count = 0\n    for _ in range(n):\n        a, b, c = map(int, input().split())\n\n        val1 = a * x1 + b * y1 + c\n        val2 = a * x2 + b * y2 + c\n\n        if (val1 > 0 and val2 < 0) or (val1 < 0 and val2 > 0):\n            count += 1\n    print(count)\n\nif __name__ == '__main__':\n    solve()"}
{"task_id": "E2H_CF1092C", "completion": "def solve():\n    n = int(input())\n    lines = [input() for _ in range(2 * n - 2)]\n\n    # Group strings by length\n    grouped_strings = [[] for _ in range(n)]\n    for s in lines:\n        grouped_strings[len(s)].append(s)\n\n    # Find the two strings of length n-1\n    s1_n_minus_1 = grouped_strings[n - 1][0]\n    s2_n_minus_1 = grouped_strings[n - 1][1]\n\n    # Candidate original strings\n    candidate_s_1 = s1_n_minus_1 + s2_n_minus_1[-1]\n    candidate_s_2 = s2_n_minus_1 + s1_n_minus_1[-1]\n\n    def check_candidate(candidate_str, all_input_strings):\n        expected_prefixes = set()\n        expected_suffixes = set()\n        for length in range(1, n):\n            expected_prefixes.add(candidate_str[:length])\n            expected_suffixes.add(candidate_str[n - length:])\n\n        # Count occurrences of each string in the input\n        input_counts = {}\n        for s in all_input_strings:\n            input_counts[s] = input_counts.get(s, 0) + 1\n\n        # Check if expected prefixes and suffixes match input counts\n        temp_input_counts = input_counts.copy()\n        \n        # Try to match prefixes\n        for p in expected_prefixes:\n            if p in temp_input_counts and temp_input_counts[p] > 0:\n                temp_input_counts[p] -= 1\n            else:\n                return False, None\n\n        # Try to match suffixes\n        for s in expected_suffixes:\n            if s in temp_input_counts and temp_input_counts[s] > 0:\n                temp_input_counts[s] -= 1\n            else:\n                return False, None\n        \n        # All counts should be zero\n        if all(count == 0 for count in temp_input_counts.values()):\n            return True, (expected_prefixes, expected_suffixes)\n        else:\n            return False, None\n\n    is_valid_1, result_1 = check_candidate(candidate_s_1, lines)\n    if is_valid_1:\n        chosen_s = candidate_s_1\n        chosen_prefixes = result_1[0]\n    else:\n        chosen_s = candidate_s_2\n        chosen_prefixes = result_1[0] # Note: result_1 would be None if is_valid_1 is False.\n                                      # This line should be:\n                                      # chosen_prefixes = check_candidate(candidate_s_2, lines)[1][0]\n                                      # But given the problem constraints, one of them must be valid.\n                                      # So if is_valid_1 is False, then candidate_s_2 must be the one.\n        is_valid_2, result_2 = check_candidate(candidate_s_2, lines)\n        chosen_prefixes = result_2[0]\n\n\n    # Construct the output string\n    output_chars = []\n    \n    # Keep track of which strings have been used as prefixes\n    # This is important for duplicates.\n    prefix_usage_counts = {p: 0 for p in chosen_prefixes}\n    \n    for input_str in lines:\n        if input_str in chosen_prefixes and prefix_usage_counts[input_str] < 1:\n            output_chars.append('P')\n            prefix_usage_counts[input_str] += 1\n        else:\n            output_chars.append('S')\n\n    print(\"\".join(output_chars))\n\nsolve()"}
{"task_id": "E2H_CF1146D", "completion": "import sys\nimport collections\n\ndef solve():\n    m, a, b = map(int, sys.stdin.readline().split())\n\n    if a == 0: # This case is not possible based on constraints (a >= 1)\n        print(1)\n        return\n\n    # dp[rem] stores the minimum position x such that x % (a+b) == rem\n    # and x is reachable. Initialize with infinity.\n    dp = collections.defaultdict(lambda: float('inf'))\n    dp[0] = 0\n\n    q = collections.deque()\n    q.append(0)\n\n    reachable_points_up_to_a_plus_b_minus_1 = []\n\n    while q:\n        u = q.popleft()\n        \n        # Jump +a\n        v_plus_a = u + a\n        rem_plus_a = v_plus_a % (a + b)\n        if v_plus_a < dp[rem_plus_a]:\n            dp[rem_plus_a] = v_plus_a\n            q.append(v_plus_a)\n        \n        # Jump -b\n        v_minus_b = u - b\n        rem_minus_b = v_minus_b % (a + b)\n        if v_minus_b < dp[rem_minus_b]:\n            dp[rem_minus_b] = v_minus_b\n            q.append(v_minus_b)\n            \n    # Collect all reachable points x where x < a+b\n    # These are points where dp[x % (a+b)] == x\n    for rem in range(a + b):\n        if dp[rem] != float('inf'):\n            reachable_points_up_to_a_plus_b_minus_1.append(dp[rem])\n    \n    reachable_points_up_to_a_plus_b_minus_1.sort()\n\n    prefix_sums_f = [0] * (a + b)\n    current_reachable_count = 0\n    \n    ptr = 0\n    for i in range(a + b):\n        while ptr < len(reachable_points_up_to_a_plus_b_minus_1) and reachable_points_up_to_a_plus_b_minus_1[ptr] <= i:\n            current_reachable_count += 1\n            ptr += 1\n        prefix_sums_f[i] = current_reachable_count\n\n    total_sum_f = 0\n\n    # Part 1: i from 0 to min(m, a+b-1)\n    for i in range(min(m, a + b - 1) + 1):\n        total_sum_f += prefix_sums_f[i]\n    \n    if m < a + b - 1:\n        print(total_sum_f)\n        return\n\n    # Part 2: i from a+b to m\n    # For i >= a+b, f(i) = f(i - (a+b)) + current_reachable_count_at_i_mod_a_plus_b\n    # Let K = a+b.\n    # f(i) = (i // K) * prefix_sums_f[K-1] + prefix_sums_f[i % K]\n    # This is incorrect.\n    # For i >= a+b, f(i) = (i // K) * (number of reachable points up to K-1) + (number of reachable points up to i % K)\n    # The number of reachable points up to K-1 is prefix_sums_f[K-1].\n    # The number of reachable points up to i % K is prefix_sums_f[i % K].\n    # This is also not quite right.\n    # f(x) = count of reachable y such that y <= x.\n    # For x >= a+b, any reachable point y <= x can be written as y = k*(a+b) + r, where r is a reachable point in [0, a+b-1].\n    # So, f(x) = count of reachable r in [0, a+b-1] such that r <= x.\n    # If r is reachable and r <= x, then k*(a+b)+r is reachable and <= x for k >= 0.\n    # The number of reachable points for a given remainder `rem` is (x - dp[rem]) // (a+b) + 1, if x >= dp[rem].\n    # This is the number of points of form dp[rem] + k*(a+b) that are <= x.\n\n    # Let N = a + b.\n    # For i >= N, f(i) = sum over all reachable rem in [0, N-1] of ( (i - dp[rem]) // N + 1 )\n    # (provided i >= dp[rem])\n    \n    # We need to calculate sum_{i=N}^{m} f(i).\n    \n    # f(i) = sum_{rem s.t. dp[rem] <= i} ( (i - dp[rem]) // N + 1 )\n    # Let K = a+b.\n    # For each reachable remainder `rem` (i.e., dp[rem] is finite):\n    # We want to sum ( (i - dp[rem]) // K + 1 ) for i from max(N, dp[rem]) to m.\n    \n    # The sum is sum_{i=N}^{m} f(i).\n    \n    # We can iterate through each reachable `rem` in `dp`.\n    for rem_val, min_pos in dp.items():\n        if min_pos == float('inf'):\n            continue\n        \n        # We consider points of the form min_pos + k * (a+b)\n        # These points are reachable.\n        \n        # We need to sum ( (i - min_pos) // (a+b) + 1 ) for i from max(a+b, min_pos) to m.\n        # This is equivalent to summing 1 for each reachable point.\n        # The number of reachable points up to i is f(i).\n        \n        # Let's count how many times each reachable point contributes to f(i).\n        # A reachable point `p` contributes to f(i) if `p <= i`.\n        # So `p` contributes to `f(p), f(p+1), ..., f(m)`.\n        # It contributes `m - p + 1` times.\n        \n        # For points `p` such that `p < a+b`:\n        # These are `reachable_points_up_to_a_plus_b_minus_1`.\n        # Their contribution to `sum_{i=0}^{min(m, a+b-1)} f(i)` is already handled.\n        # For `i` from `a+b` to `m`:\n        # Each `p` in `reachable_points_up_to_a_plus_b_minus_1` contributes to `f(i)` if `p <= i`.\n        # So it contributes to `f(a+b), ..., f(m)`.\n        # The number of times `p` contributes is `m - max(p, a+b) + 1`.\n        # Since `p < a+b`, this is `m - (a+b) + 1`.\n        \n        # This is for points `p` in `[0, a+b-1]`.\n        # What about points `p'` that are `min_pos + k*(a+b)` where `k > 0`?\n        # These points are `p' >= a+b`.\n        # They contribute to `f(i)` for `i` from `p'` to `m`.\n        # The number of times `p'` contributes is `m - p' + 1`.\n        \n        # So the total sum is sum_{reachable p <= m} (m - p + 1).\n\n    # Sum for i from 0 to min(m, a+b-1) is already `total_sum_f`.\n    # Now we need to add contributions for i from `a+b` to `m`.\n    \n    # For i in range(a+b, m+1):\n    #   f(i) = sum_{rem_val, min_pos in dp.items()} ( (i - min_pos) // (a+b) + 1 ) if i >= min_pos\n    # This is equivalent to:\n    # f(i) = sum_{rem_val, min_pos in dp.items() such that min_pos <= i} (floor((i - min_pos) / (a+b))) + count of such min_pos\n    # Let count_reachable_up_to_i = prefix_sums_f[i % (a+b)] + (i // (a+b)) * prefix_sums_f[a+b-1] (if i >= a+b)\n    # This is not exactly correct.\n\n    # Let's re-evaluate f(i) for i >= a+b.\n    # f(i) is the number of distinct reachable points `p` such that `p <= i`.\n    # These points are of the form `dp[rem] + k * (a+b)` for some `k >= 0`.\n    # So `dp[rem] + k * (a+b) <= i`.\n    # `k * (a+b) <= i - dp[rem]`.\n    # `k <= (i - dp[rem]) / (a+b)`.\n    # So for a given `rem`, the number of such points is `floor((i - dp[rem]) / (a+b)) + 1` (if `i >= dp[rem]`).\n    # If `i < dp[rem]`, it's 0.\n    \n    # So for `i >= a+b`:\n    # f(i) = sum_{rem such that dp[rem] <= i} (floor((i - dp[rem]) / (a+b)) + 1)\n    \n    # We need sum_{i=a+b}^{m} f(i).\n    # Let K = a+b.\n    # Sum = sum_{i=K}^{m} sum_{rem such that dp[rem] <= i} (floor((i - dp[rem]) / K) + 1)\n    \n    # Change order of summation:\n    # Sum = sum_{rem such that dp[rem] <= m} sum_{i=max(K, dp[rem])}^{m} (floor((i - dp[rem]) / K) + 1)\n    \n    # Let `min_pos = dp[rem]`.\n    # We need to compute sum_{i=max(K, min_pos)}^{m} (floor((i - min_pos) / K) + 1)\n    \n    # Let `start_i = max(K, min_pos)`.\n    # Let `j = i - min_pos`.\n    # The sum becomes sum_{j=start_i - min_pos}^{m - min_pos} (floor(j / K) + 1)\n    \n    # Let `L = start_i - min_pos` and `R = m - min_pos`.\n    # We need sum_{j=L}^{R} (floor(j / K) + 1).\n    \n    # This is a sum of an arithmetic progression of floor values.\n    # sum_{j=L}^{R} (floor(j / K) + 1) = (R - L + 1) + sum_{j=L}^{R} floor(j / K)\n    \n    # sum_{j=L}^{R} floor(j / K) can be computed efficiently.\n    # It's (sum_{j=0}^{R} floor(j/K)) - (sum_{j=0}^{L-1} floor(j/K)).\n    \n    # sum_{j=0}^{X} floor(j / K) = K * sum_{q=0}^{floor(X/K)-1} q + (floor(X/K)) * (X % K + 1)\n    # = K * (floor(X/K) - 1) * floor(X/K) / 2 + (floor(X/K)) * (X % K + 1)\n    # This can be simplified.\n    # Let `q_max = floor(X / K)`.\n    # The sum is K * (0 + 1 + ... + (q_max - 1)) + q_max * (X % K + 1)\n    # = K * (q_max - 1) * q_max / 2 + q_max * (X % K + 1)\n    # Let's use a helper function for this sum.\n    \n    def sum_floor_j_div_K(X, K):\n        if X < 0:\n            return 0\n        q_max = X // K\n        # Sum of q for q from 0 to q_max - 1, each repeated K times\n        # Plus q_max repeated (X % K + 1) times\n        \n        # sum_{j=0 to X} floor(j/K)\n        # 0 for j=0 to K-1 (K terms)\n        # 1 for j=K to 2K-1 (K terms)\n        # ...\n        # q_max-1 for j=(q_max-1)K to q_max*K-1 (K terms)\n        # q_max for j=q_max*K to X (X - q_max*K + 1 terms)\n        \n        term1 = K * (q_max - 1) * q_max // 2\n        term2 = q_max * (X % K + 1)\n        return term1 + term2\n\n    K = a + b\n    \n    for rem_val, min_pos in dp.items():\n        if min_pos == float('inf'):\n            continue\n        \n        # We need to sum for i from max(K, min_pos) to m.\n        start_i = max(K, min_pos)\n        \n        if start_i > m: # No contribution for this min_pos\n            continue\n            \n        L = start_i - min_pos\n        R = m - min_pos\n        \n        count_terms = R - L + 1\n        \n        # Add (R - L + 1) for the \"+1\" part in (floor(j/K) + 1)\n        total_sum_f += count_terms\n        \n        # Add sum_{j=L}^{R} floor(j / K)\n        total_sum_f += sum_floor_j_div_K(R, K) - sum_floor_j_div_K(L - 1, K)\n\n    print(total_sum_f)\n\nsolve()"}
{"task_id": "E2H_CF980E", "completion": "import sys\n\ndef solve():\n    n, k = map(int, sys.stdin.readline().split())\n    adj = [[] for _ in range(n + 1)]\n    for _ in range(n - 1):\n        u, v = map(int, sys.stdin.readline().split())\n        adj[u].append(v)\n        adj[v].append(u)\n\n    # We want to keep n - k nodes.\n    # To maximize sum of 2^i, we want to keep nodes with larger i.\n    # This means we should remove nodes with smaller i.\n    # The remaining nodes must form a connected component.\n\n    # Start by assuming all nodes are kept.\n    # We want to remove k nodes with the smallest indices, such that the remaining graph is connected.\n\n    # Find the node with the largest index that we must keep.\n    # This node will be the \"root\" of our connected component.\n    # If we remove nodes 1, 2, ..., n-k, the remaining component is just node n-k+1.\n    # This is not necessarily connected.\n\n    # The strategy is to iteratively remove the smallest indexed node that can be removed\n    # without disconnecting the graph or making it impossible to form a connected component of size n-k.\n\n    # A simpler approach:\n    # We want to keep a connected component of size N_kept = n - k.\n    # To maximize the sum of 2^i, we should try to keep the N_kept largest indices.\n    # This is not always possible.\n    # Instead, we should remove the smallest indices first.\n\n    # Let's consider the nodes in decreasing order of their index.\n    # The largest index node, n, is always a good candidate to keep.\n    # We want to keep a connected component of size N_kept = n - k.\n    # We will try to keep node `n` and then expand from it.\n\n    # We can use a BFS/DFS from node `n` to find a connected component of size `n - k`.\n    # However, this doesn't guarantee maximizing the sum.\n    # The problem asks to maximize the sum, which means keeping larger indices.\n\n    # The core idea: we want to remove k nodes.\n    # We should prioritize removing nodes with smaller indices.\n    # The crucial constraint is that the remaining n-k nodes must form a connected component.\n\n    # Let's try a greedy approach.\n    # Maintain a set of `kept` nodes, initially empty.\n    # Iterate `i` from `n` down to `1`.\n    # If `i` can be added to `kept` such that `kept` remains connected (or can be made connected later)\n    # and `len(kept) < n - k`, add `i` to `kept`.\n\n    # This seems complicated. Let's rethink.\n    # We want to remove k nodes.\n    # The nodes we remove should have the smallest possible indices.\n    # We need to find a connected component of size `n - k` that has the maximum sum of `2^i`.\n    # This is equivalent to finding a connected component of size `n - k` that has the minimum sum of `i` (because `2^i` is strictly increasing).\n    # So, we want to keep nodes with large indices.\n\n    # Let `S` be the set of nodes we keep. `|S| = n - k`.\n    # We want to maximize `sum(2^i for i in S)`.\n    # This means we want `S` to contain as many large indices as possible.\n\n    # Consider the node `n`. It's always beneficial to keep `n`.\n    # What if we don't keep `n`? Then we'd need to keep `n-1`, `n-2`, etc.\n    # This seems like a tree DP problem or a greedy approach.\n\n    # Let's consider the nodes we want to remove.\n    # We want to remove `k` nodes.\n    # We iterate from `i = 1` to `n`. If node `i` can be removed, remove it.\n    # A node `i` can be removed if:\n    # 1. We still need to remove more nodes (`removed_count < k`).\n    # 2. Removing `i` does not disconnect the remaining graph such that it's impossible to form a connected component of size `n - k`.\n\n    # This is a standard problem: find a connected subgraph of size `n-k` with maximum sum of weights.\n    # If weights are `2^i`, then we want to keep nodes with large `i`.\n    # This is equivalent to finding a connected subgraph of size `n-k` with minimum sum of weights `2^i` if we choose to remove `k` nodes.\n    # Or, equivalently, finding a connected subgraph of size `n-k` with minimum sum of `(-2^i)` if we choose to keep `n-k` nodes.\n\n    # Let's try the greedy approach based on removing smallest indices.\n    # We need to maintain connectivity.\n    # We can use a Disjoint Set Union (DSU) or keep track of the current connected component.\n\n    # The most common approach for this type of problem is to iterate through nodes from `n` down to `1`.\n    # We try to keep as many large-indexed nodes as possible.\n    # The node `n` is definitely kept.\n    # We will try to keep `n-1`, `n-2`, ..., until we have `n-k` nodes.\n    # But we need to ensure connectivity.\n\n    # Let's fix the \"root\" of our desired connected component.\n    # The \"root\" should be the largest indexed node in the component.\n    # Let `R` be this root.\n    # Then all other `n-k-1` nodes must be connected to `R` (directly or indirectly)\n    # and have indices smaller than `R`.\n    # This is still not quite right, as `R` doesn't have to be the largest index.\n    # It's just that if we pick a set of nodes, the largest index among them is `max(S)`.\n\n    # The problem can be rephrased as: select `n-k` nodes that form a connected component\n    # and maximize `sum(2^i)`.\n    # This means we want to keep nodes with large indices.\n    # So, we should try to remove nodes with small indices.\n\n    # Let's maintain a set of `removed` nodes.\n    # Initially, `removed` is empty.\n    # We iterate `i` from `1` to `n`.\n    # If `i` can be removed, and `len(removed) < k`, we remove `i`.\n    # When can `i` be removed?\n    # `i` can be removed if removing it does not split the graph into more than one component,\n    # and the largest component formed still has size at least `n-k`.\n    # This is hard to check efficiently.\n\n    # Consider the node `n`. It's always good to keep it.\n    # Let's find the `n-k` nodes that form the desired component.\n    # A common technique for \"remove k nodes to maximize sum\" in trees is to root the tree arbitrarily (e.g., at node 1).\n    # Then for each node `u`, calculate `dp[u][j]` = max sum of `2^i` in a connected component of size `j` rooted at `u`\n    # (where `u` is the highest node in the component). This is too complex.\n\n    # A simpler greedy approach:\n    # We want to remove `k` nodes.\n    # We iterate from `i = 1` to `n`.\n    # For each node `i`, we check if it's possible to remove `i` and still form a connected component of size `n-k` from the remaining nodes,\n    # and if we still need to remove nodes (`removed_count < k`).\n    # If we remove `i`, we add it to a `removed_nodes` list.\n\n    # How to check if removing `i` is \"safe\"?\n    # The total number of nodes to keep is `n_kept = n - k`.\n    # We must select `n_kept` nodes that form a connected component.\n    # To maximize the sum, we should select `n_kept` nodes with the largest possible indices.\n    # This implies we should try to remove nodes with small indices.\n\n    # Let's try to remove node `i` if `i` is a leaf and `i` is not `n` (or some other 'important' node).\n    # This is specific to leaves. What if `i` is not a leaf?\n\n    # Consider the nodes in decreasing order `n, n-1, ..., 1`.\n    # We maintain a set `current_component` of nodes we are keeping.\n    # Initially, `current_component = {n}`.\n    # `removed_count = 0`.\n    # `removed_nodes = []`.\n\n    # This is the crucial insight for this type of problem (maximize sum by removing k nodes, connectivity constraint):\n    # The optimal set of `n-k` nodes forms a connected component.\n    # There must be a \"highest\" node in this component (e.g., node with largest index).\n    # Let this node be `max_node`.\n    # All other `n-k-1` nodes must be \"reachable\" from `max_node` without passing through any removed nodes.\n    # This means `max_node` is the \"root\" of the component.\n\n    # The \"root\" node of the component is not necessarily the node with the largest index.\n    # It's the node with the largest index among the `n-k` nodes we keep.\n    # Let this node be `R`.\n    # All `n-k` nodes must form a connected component.\n    # We want to maximize `sum(2^i)`.\n    # This implies we want to keep `R` as large as possible.\n\n    # The actual greedy strategy for this problem:\n    # We want to remove `k` nodes.\n    # We should always try to remove the smallest indexed node first.\n    # Let `removed_nodes` be the list of nodes to remove.\n    # We iterate `i` from `1` to `n`.\n    # If `i` is not `n` (the largest index node) and `len(removed_nodes) < k`,\n    # we try to remove `i`.\n    # A node `i` can be removed if, after removing it, the remaining `n - 1 - len(removed_nodes)` nodes\n    # can still form a connected component of size `n - k`.\n    # This means the largest connected component in `G - {i} - removed_nodes` must be at least `n - k`.\n\n    # This is too complicated to check dynamically.\n    # A common variant: find the node `x` such that removing `x` causes the least \"damage\" to connectivity\n    # while also having a small index.\n\n    # Let's consider the final set of `n-k` nodes.\n    # Let `S` be this set. `S` must be connected.\n    # We want to maximize `sum(2^i for i in S)`.\n    # This means we want `S` to contain nodes with large indices.\n    # The `k` nodes we remove should be nodes with small indices.\n\n    # The critical observation for these problems is often related to the node `n`.\n    # Node `n` has the largest fan count. We almost certainly want to keep it.\n    # If we keep node `n`, then we need to find `n-k-1` other nodes\n    # that form a connected component with `n`, and maximize their sum.\n    # These `n-k-1` nodes should also have large indices.\n\n    # What if we iterate from `i = n` down to `1`?\n    # We try to keep `i`.\n    # `kept_nodes = set()`\n    # `removed_nodes = []`\n    # `parent = {}`\n    # `size = {}`\n    # `find(x)`: returns representative of `x`\n    # `union(x, y)`: merges sets containing `x` and `y`\n\n    # This problem is a variant of \"remove k nodes to maximize value, maintain connectivity\".\n    # The standard approach is to process nodes in decreasing order of value (index in this case).\n    # We want to keep `n-k` nodes.\n    # Let `nodes_to_keep = n - k`.\n    # `current_kept_count = 0`\n    # `removed_nodes_list = []`\n    # `is_kept = [False] * (n + 1)`\n\n    # We iterate `i` from `n` down to `1`.\n    # For each `i`, we try to keep it.\n    # If we keep `i`, we add it to a potential component.\n    # We need to ensure that the final component is connected and has `n-k` nodes.\n\n    # The greedy strategy that works for this problem:\n    # 1. Initialize `removed_count = 0` and `removed_nodes = []`.\n    # 2. Iterate `i` from `1` to `n`.\n    # 3. For each `i`, check if it can be removed.\n    #    A node `i` can be removed if:\n    #    a. `removed_count < k` (we still need to remove nodes).\n    #    b. Removing `i` does not disconnect the graph such that it's impossible to form a connected component of size `n-k` using the remaining nodes.\n    #    This condition `b` is tricky.\n\n    # A simpler interpretation of condition `b`:\n    # If we remove `i`, the remaining `n - 1` nodes (and potentially other already removed nodes)\n    # must still contain a connected component of size `n - k`.\n    # This is equivalent to saying that `i` is not a \"bridge\" or an \"articulation point\"\n    # that prevents us from forming a large enough component.\n\n    # The actual correct greedy approach for this problem:\n    # We want to keep `N_kept = n - k` nodes.\n    # We want to remove `k` nodes.\n    # We should remove the `k` nodes with the smallest indices, such that the remaining `N_kept` nodes form a connected component.\n\n    # Consider the nodes in increasing order `1, 2, ..., n`.\n    # We maintain a set `kept_nodes` which initially contains all nodes.\n    # We also maintain a `removed_count`.\n    # For each node `i` from `1` to `n-1`:\n    #   If `removed_count == k`, break.\n    #   Try to remove `i`.\n    #   To check if `i` can be removed:\n    #     Temporarily remove `i` from the graph.\n    #     Check if there is *any* connected component of size at least `N_kept` in the remaining graph.\n    #     If yes, remove `i` permanently, increment `removed_count`.\n    #     If no, `i` cannot be removed (it's essential for forming a large enough component).\n\n    # This check (finding largest component) is too slow for each `i`. `O(N)` times `O(N+M)`.\n    # `N=10^6` so `N^2` is too slow.\n\n    # What if we iterate from `n` down to `1`?\n    # We want to keep `n-k` nodes.\n    # We definitely want to keep node `n`.\n    # Let `kept_nodes = {n}`.\n    # `nodes_to_remove = []`\n    # `visited = [False] * (n + 1)`\n    # `visited[n] = True`\n    # `q = collections.deque([n])`\n    # `component_size = 1`\n\n    # This is a BFS/DFS from node `n` to find `n-k` nodes.\n    # We want to find the `n-k` nodes that are connected to `n` and maximize sum.\n    # This means we should prioritize neighbors of `n` with large indices.\n    # This is exactly what the example shows:\n    # N=6, K=3. Keep 3 nodes.\n    # Graph: 1-2, 6-2, 4-2, 5-6, 2-3\n    # Nodes: 1,2,3,4,5,6\n    # Keep 3 nodes. Maximize sum.\n    # Output: 1 3 4 (removed). Kept: 2 5 6. Sum: 2^2 + 2^5 + 2^6 = 4 + 32 + 64 = 100.\n    # The component is 2-6-5. This is connected. Size 3.\n    # Notice node 2 is not the largest index. Node 6 is.\n    # The component is {2, 5, 6}. `max(S) = 6`.\n\n    # The problem is a variation of finding a connected subgraph of a certain size.\n    # The general strategy for \"remove k nodes with min sum to keep connected component of size N-k\" is:\n    # 1. Start with the full graph.\n    # 2. Maintain a set of `removed_nodes` (initially empty).\n    # 3. Iterate `i` from `1` to `n`.\n    # 4. If `removed_count == k`, stop.\n    # 5. Check if `i` can be removed.\n    #    `i` can be removed if, after removing `i` (and all previously removed nodes),\n    #    the largest connected component in the remaining graph has size at least `n-k`.\n    #    If yes, add `i` to `removed_nodes`, `removed_count++`.\n    #    If no, `i` cannot be removed.\n\n    # How to efficiently check condition 5?\n    # We can use a Disjoint Set Union (DSU) structure.\n    # Initialize DSU with all `n` nodes. Each node is its own set, size 1.\n    # `max_component_size = n`.\n    # `nodes_to_keep = n - k`.\n\n    # When we consider removing node `i`:\n    # If `i` is removed, it effectively splits its neighbors.\n    # The DSU approach works if we add nodes.\n    # If we remove nodes, it's harder.\n\n    # Let's consider the nodes we *keep*.\n    # We want to keep `n-k` nodes.\n    # We want to keep the largest possible indices.\n    # So, we iterate from `i = n` down to `1`.\n    # We try to add `i` to our `kept_nodes` set.\n    # `kept_nodes = set()`\n    # `removed_nodes = []`\n    # `current_nodes_in_component = 0`\n\n    # This is a known problem pattern. The solution involves finding the \"root\" of the desired component.\n    # The \"root\" is the node with the largest index among the `n-k` nodes we keep.\n    # Let this node be `R`.\n    # We want to find `R` such that `R` is as large as possible.\n    # Once `R` is fixed, we need to find `n-k-1` other nodes connected to `R` (directly or indirectly)\n    # that maximize `sum(2^j)`. These `n-k-1` nodes must have indices less than `R`.\n    # This is a BFS/DFS from `R` where we greedily pick neighbors with largest indices.\n\n    # This problem can be solved by iterating from node `n` downwards.\n    # We maintain a set of nodes that we have decided to keep.\n    # We also keep track of their connectivity using a DSU or by running BFS/DFS from `n`.\n\n    # Let `kept_count = 0`.\n    # `removed_list = []`.\n    # `is_removed = [False] * (n + 1)`.\n\n    # Iterate `i` from `n` down to `1`.\n    # If `kept_count < n - k`:\n    #   Add `i` to the `kept_nodes` set.\n    #   `kept_count += 1`.\n    # Else (we have `n-k` nodes already tentatively kept):\n    #   We want to remove `i` if possible.\n    #   `removed_list.append(i)`.\n    #   `is_removed[i] = True`.\n\n    # After this initial pass, `kept_nodes` contains `n, n-1, ..., k+1`.\n    # `removed_list` contains `1, 2, ..., k`.\n    # This is the ideal situation. But is the set `{k+1, ..., n}` connected?\n    # If it is, then this is the answer.\n    # If not, we need to adjust.\n\n    # Example 1: N=6, K=3. Keep 3 nodes.\n    # Initial kept: {6, 5, 4}. Removed: {1, 2, 3}.\n    # Is {4, 5, 6} connected?\n    # 4-2, 5-6, 6-2.\n    # In original graph: 4 is connected to 2. 5 is connected to 6. 6 is connected to 2.\n    # If we remove 1, 2, 3:\n    # 4 is isolated. 5-6 is a component.\n    # So {4, 5, 6} is NOT connected. We cannot remove 1, 2, 3.\n\n    # The actual approach for this problem is usually based on \"peeling\" off nodes.\n    # We want to remove `k` nodes.\n    # We want to remove nodes with small indices.\n    # We use a DSU structure to keep track of connected components.\n    # Or, we can use a simpler approach:\n    # Start with all nodes.\n    # We need to remove `k` nodes.\n    # The `n-k` nodes we keep must form a connected component.\n    # This means there must be a \"core\" component.\n\n    # Consider the nodes in increasing order of index `1, 2, ..., n`.\n    # We maintain a list of `removed_nodes`.\n    # For each node `i` from `1` to `n`:\n    #   If `len(removed_nodes) == k`, break.\n    #   If `i` is a candidate for removal:\n    #     We tentatively remove `i`.\n    #     Then, count the size of the largest connected component in the remaining graph.\n    #     If this size is `>= n - k`, then `i` can be removed. Add `i` to `removed_nodes`.\n    #     If not, `i` must be kept.\n\n    # This check is too slow.\n    # The trick for this problem is often to iterate from `n` down to `1`.\n    # We need to find `n-k` nodes.\n    # Let `kept_count = 0`.\n    # `kept_set = set()`.\n    # `removed_set = set()`.\n\n    # We iterate `i` from `n` down to `1`.\n    # If `kept_count == n - k`, then all remaining nodes `1, ..., i` must be removed.\n    # So we add them to `removed_set` and break.\n    # Otherwise, we consider node `i`.\n    # We want to keep `i`.\n    # Add `i` to `kept_set`. `kept_count += 1`.\n    # This greedy choice is not enough because it doesn't guarantee connectivity.\n\n    # This is a classic \"peeling\" or \"leaf removal\" type of problem.\n    # We want to keep a connected component of size `n-k`.\n    # The nodes we remove are those that are \"redundant\" or \"peripheral\" and have small indices.\n    # We can start by marking all nodes as \"to be kept\".\n    # We maintain a count of nodes to remove `rem_count = k`.\n    # We also maintain a `degree` array for the current graph (nodes not yet removed).\n    # Initialize `degree[i]` for all `i` based on the input graph.\n    # Use a priority queue (min-heap) to store nodes that are \"removable\".\n    # A node `i` is \"removable\" if its degree is 1 (it's a leaf) and it's not the last remaining node.\n    # Or, more generally, if removing it doesn't split the graph into too many components.\n\n    # A simpler greedy approach, which works for this specific problem (maximize sum of 2^i):\n    # We want to keep `N_kept = n - k` nodes.\n    # The nodes with larger indices are more valuable.\n    # Let's assume we *must* keep node `n` (the largest index).\n    # Then we need to find `N_kept - 1` other nodes that are connected to `n` (or to each other, forming a path to `n`).\n    # We can perform a BFS/DFS starting from `n`.\n    # When exploring from a node `u` to its neighbor `v`, we prefer to visit `v` if `v` has a larger index.\n    # This is essentially a \"greedy BFS/DFS\" for finding the component.\n\n    # Let's try the BFS approach:\n    # `kept_nodes = set()`\n    # `q = collections.deque()`\n    # `visited = [False] * (n + 1)`\n\n    # Add `n` to `kept_nodes`. `visited[n] = True`. `q.append(n)`.\n    # `current_component_size = 1`.\n\n    # While `q` is not empty and `current_component_size < n - k`:\n    #   `u = q.popleft()`\n    #   Consider neighbors `v` of `u`.\n    #   We want to add neighbors with large indices.\n    #   Sort `adj[u]` in descending order.\n    #   For `v` in `sorted(adj[u], reverse=True)`:\n    #     If `not visited[v]`:\n    #       `visited[v] = True`\n    #       `kept_nodes.add(v)`\n    #       `q.append(v)`\n    #       `current_component_size += 1`\n    #       If `current_component_size == n - k`, break both loops.\n    #   If `current_component_size == n - k`, break outer loop.\n\n    # This BFS will find a connected component of size `n-k` starting from `n`,\n    # prioritizing larger indices. This seems like a plausible greedy strategy.\n    # Let's test this with Example 1: N=6, K=3. Keep 3 nodes.\n    # adj: 1:[2], 2:[1,6,4,3], 3:[2], 4:[2], 5:[6], 6:[2,5]\n\n    # Start with n=6.\n    # `kept_nodes = {6}`. `q = [6]`. `visited[6]=True`. `current_component_size = 1`.\n\n    # `u = 6`. Neighbors of 6: [2, 5]. Sorted: [5, 2].\n    #   `v = 5`. `not visited[5]`.\n    #     `visited[5]=True`. `kept_nodes.add(5)`. `q.append(5)`. `current_component_size = 2`.\n    #   `v = 2`. `not visited[2]`.\n    #     `visited[2]=True`. `kept_nodes.add(2)`. `q.append(2)`. `current_component_size = 3`.\n    #     `current_component_size == n-k` (3 == 3). Break.\n\n    # `kept_nodes = {6, 5, 2}`.\n    # Removed nodes are `all_nodes - kept_nodes`: `{1, 2, 3, 4, 5, 6} - {2, 5, 6} = {1, 3, 4}`.\n    # This matches the example output!\n\n    # Let's try Example 2: N=8, K=4. Keep 4 nodes.\n    # adj:\n    # 1: [2, 3]\n    # 2: [6, 7, 1, 4]\n    # 3: [1]\n    # 4: [2]\n    # 5: [7]\n    # 6: [2]\n    # 7: [8, 2, 5]\n    # 8: [7]\n\n    # Start with n=8.\n    # `kept_nodes = {8}`. `q = [8]`. `visited[8]=True`. `current_component_size = 1`.\n\n    # `u = 8`. Neighbors of 8: [7]. Sorted: [7].\n    #   `v = 7`. `not visited[7]`.\n    #     `visited[7]=True`. `kept_nodes.add(7)`. `q.append(7)`. `current_component_size = 2`.\n    #     `current_component_size < n-k` (2 < 4). Continue.\n\n    # `u = 7`. Neighbors of 7: [8, 2, 5]. Sorted: [8, 5, 2].\n    #   `v = 8`. `visited[8]`. Skip.\n    #   `v = 5`. `not visited[5]`.\n    #     `visited[5]=True`. `kept_nodes.add(5)`. `q.append(5)`. `current_component_size = 3`.\n    #     `current_component_size < n-k` (3 < 4). Continue.\n    #   `v = 2`. `not visited[2]`.\n    #     `visited[2]=True`. `kept_nodes.add(2)`. `q.append(2)`. `current_component_size = 4`.\n    #     `current_component_size == n-k` (4 == 4). Break.\n\n    # `kept_nodes = {8, 7, 5, 2}`.\n    # Removed nodes: `{1, 2, 3, 4, 5, 6, 7, 8} - {2, 5, 7, 8} = {1, 3, 4, 6}`.\n    # Example output: `1 3 4 5`. My output `1 3 4 6`. These are different.\n    # The example output implies `kept_nodes = {2, 6, 7, 8}`.\n    # Sum for {2, 5, 7, 8}: 2^2 + 2^5 + 2^7 + 2^8 = 4 + 32 + 128 + 256 = 420.\n    # Sum for {2, 6, 7, 8}: 2^2 + 2^6 + 2^7 + 2^8 = 4 + 64 + 128 + 256 = 452.\n    # The example output has a higher sum! So my greedy BFS is not correct.\n\n    # The problem is that the \"root\" of the component (the node with the largest index) is not necessarily `n`.\n    # Or, if `n` is the root, then the BFS order of adding neighbors might not be optimal.\n    # The BFS explored `u` then its neighbors. But it should prioritize adding the largest possible index *overall*, not just among neighbors of `u`.\n    # This suggests a priority queue (max-heap) approach.\n\n    # Let's try again with a priority queue.\n    # We want to keep `N_kept = n - k` nodes.\n    # We use a max-heap to store candidate nodes to add to our component.\n    # Initially, add `n` to the `kept_nodes` set and to the max-heap.\n    # `kept_nodes = set()`\n    # `pq = []` (max-heap, so store negative values or tuples `(-value, value)`)\n    # `visited = [False] * (n + 1)`\n\n    # `heapq.heappush(pq, -n)`\n    # `visited[n] = True`\n    # `kept_nodes.add(n)`\n    # `current_component_size = 1`\n\n    # While `pq` is not empty and `current_component_size < n - k`:\n    #   `u = -heapq.heappop(pq)`\n    #   For `v` in `adj[u]`:\n    #     If `not visited[v]`:\n    #       `visited[v] = True`\n    #       `kept_nodes.add(v)`\n    #       `heapq.heappush(pq, -v)`\n    #       `current_component_size += 1`\n    #       If `current_component_size == n - k`, break both loops.\n    #   If `current_component_size == n - k`, break outer loop.\n\n    # Let's trace Example 2 with this priority queue approach:\n    # N=8, K=4. Keep 4 nodes.\n    # `kept_nodes = set()`. `pq = []`. `visited = [F]*9`.\n    # `heapq.heappush(pq, -8)`. `visited[8]=True`. `kept_nodes.add(8)`. `current_component_size = 1`.\n\n    # Loop 1: `pq = [-8]`. `current_component_size = 1 < 4`.\n    #   `u = 8`.\n    #   Neighbors of 8: [7].\n    #     `v = 7`. `not visited[7]`.\n    #       `visited[7]=True`. `kept_nodes.add(7)`. `heapq.heappush(pq, -7)`. `current_component_size = 2`.\n    #       `current_component_size < 4`. Continue.\n    #   `pq = [-7]`. `kept_nodes = {8, 7}`.\n\n    # Loop 2: `pq = [-7]`. `current_component_size = 2 < 4`.\n    #   `u = 7`.\n    #   Neighbors of 7: [8, 2, 5].\n    #     `v = 8`. `visited[8]`. Skip.\n    #     `v = 2`. `not visited[2]`.\n    #       `visited[2]=True`. `kept_nodes.add(2)`. `heapq.heappush(pq, -2)`. `current_component_size = 3`.\n    #       `current_component_size < 4`. Continue.\n    #     `v = 5`. `not visited[5]`.\n    #       `visited[5]=True`. `kept_nodes.add(5)`. `heapq.heappush(pq, -5)`. `current_component_size = 4`.\n    #       `current_component_size == 4`. Break inner loop.\n    #   `current_component_size == 4`. Break outer loop.\n\n    # `kept_nodes = {8, 7, 2, 5}`.\n    # Removed nodes: `{1, 3, 4, 6}`.\n    # Still not matching example output `{1, 3, 4, 5}`.\n    # The example output means `kept_nodes = {2, 6, 7, 8}`.\n\n    # Why is my result different from example?\n    # My `kept_nodes = {2, 5, 7, 8}`. Sum = 420.\n    # Example `kept_nodes = {2, 6, 7, 8}`. Sum = 452.\n    # The example output is better.\n    # My priority queue approach adds 5 (index 5) before 6 (index 6).\n    # This is because 5 is a neighbor of 7, which was popped.\n    # And 6 is a neighbor of 2.\n    # When 7 was popped, its neighbors 2 and 5 were added to PQ. PQ becomes [-5, -2] (or [-2, -5] depending on tie-breaking).\n    # Then when 2 is popped, its neighbor 6 is added.\n    # The issue is that the standard priority queue BFS/Dijkstra-like approach explores based on \"distance\" or \"cost\".\n    # Here, the \"cost\" is the index itself.\n\n    # The problem is that the \"root\" of the component might not be `n`.\n    # What if `n` is removed? This is possible if `k` is large enough.\n    # But `k < n`, so at least one node is kept.\n    # To maximize `sum(2^i)`, we want to keep `n` if possible.\n\n    # The problem can be rephrased: remove `k` nodes such that the remaining graph has a connected component of size `n-k` with maximum sum of `2^i`.\n    # This is equivalent to finding a connected component of size `n-k` that maximizes `sum(2^i)`.\n\n    # The correct approach for this problem type is usually a greedy one based on degrees.\n    # We want to remove `k` nodes.\n    # We want to remove nodes with smallest indices first.\n    # A node is a good candidate for removal if it's a leaf (degree 1) or if its removal doesn't disconnect the graph \"too much\".\n\n    # Let `nodes_to_keep = n - k`.\n    # We maintain `current_degrees` for all nodes.\n    # `removed_nodes = set()`.\n    # `q = collections.deque()`.\n\n    # Initialize `current_degrees` for all nodes.\n    # Add all leaves (nodes with degree 1) to `q`.\n    # `visited_for_removal = [False] * (n + 1)`.\n\n    # While `q` is not empty and `len(removed_nodes) < k`:\n    #   `u = q.popleft()`.\n    #   If `u` is `n` (the largest node) and `len(removed_nodes) == k-1`:\n    #     This means `n` is the last node we *could* remove. But we want to keep `n` if possible.\n    #     If `n` is a leaf and we have `k-1` nodes already removed, then we are forced to remove `n` if `k` nodes must be removed.\n    #     This specific check for `n` is important.\n    #   If `u` is not `n` (or if it's `n` but we are forced to remove it as the `k`-th node) and `len(removed_nodes) < k`:\n    #     Add `u` to `removed_nodes`.\n    #     For each neighbor `v` of `u`:\n    #       `current_degrees[v] -= 1`.\n    #       If `current_degrees[v] == 1` and `v` not in `removed_nodes`:\n    #         `q.append(v)`.\n\n    # This \"leaf-peeling\" approach typically removes nodes from the periphery.\n    # It works for finding the largest connected component.\n    # Here, we want to maximize sum of `2^i`, so we want to remove smallest `i`.\n    # So, we should prioritize removing leaves with small indices.\n\n    # Let's refine the leaf-peeling strategy:\n    # `current_degree = [0] * (n + 1)`\n    # For `u` from `1` to `n`:\n    #   `current_degree[u] = len(adj[u])`\n\n    # `removable_leaves = []` (min-heap of node indices)\n    # For `i` from `1` to `n`:\n    #   If `current_degree[i] == 1`:\n    #     `heapq.heappush(removable_leaves, i)`\n\n    # `removed_nodes = set()`\n    # `nodes_to_keep_count = n`\n\n    # While `len(removed_nodes) < k` and `nodes_to_keep_count > n - k`:\n    #   If `len(removable_leaves) == 0`:\n    #     # This means no more leaves to remove.\n    #     # All remaining nodes have degree >= 2 (they form a cycle or a path with multiple branches).\n    #     # We need to remove more nodes, but we can't just pick leaves.\n    #     # This scenario means we must remove an internal node.\n    #     # The problem guarantees a tree, so this shouldn't happen unless `nodes_to_keep_count == 1`.\n    #     # In a tree, if `nodes_to_keep_count > 1`, there must be at least two leaves.\n    #     # This implies `nodes_to_keep_count` will always be greater than 1.\n    #     # Except if we have a single node left.\n    #     break\n\n    #   `u = heapq.heappop(removable_leaves)`\n\n    #   If `u` is `n` and `nodes_to_keep_count == n - k + 1`:\n    #     # If `n` is the last node we could remove to reach `n-k` nodes,\n    #     # and it's a leaf, we must remove it if we want to remove `k` nodes.\n    #     # But we want to keep `n` if possible.\n    #     # This condition means we have `n-k+1` nodes remaining, and `n` is a leaf among them.\n    #     # If we remove `n`, we will have `n-k` nodes.\n    #     # However, we want to keep `n` if possible to maximize the sum.\n    #     # So, if `u` is `n` and it's the `k`-th node to be removed, we should NOT remove it.\n    #     # Instead, we should find another node to remove.\n    #     # But `removable_leaves` only contains leaves.\n    #     # This means `n` is the *only* leaf left, and we are forced to remove it.\n    #     # This implies `nodes_to_keep_count` is 2, and `n` is one of them.\n    #     # The other node is its neighbor.\n    #     # This is tricky.\n\n    #     # If `u` is `n` and `nodes_to_keep_count` is `n-k+1`,\n    #     # and we still need to remove one more node (`len(removed_nodes) == k-1`).\n    #     # If we remove `n`, we get `n-k` nodes.\n    #     # We should only remove `n` if there is no other option.\n    #     # But we prioritize removing smaller indices. So `u` being `n` means it's the largest index leaf.\n    #     # We should not remove `n` if we can avoid it.\n    #     # This means we should skip `u` if `u == n` and `len(removed_nodes) < k`.\n    #     # Instead, we should find the next smallest node that is not `n` and is a leaf.\n    #     # This means we need to handle `n` as a special case.\n\n    #     # A more robust leaf-peeling:\n    #     # We want to keep `n-k` nodes.\n    #     # We iterate `i` from `1` to `n-1`.\n    #     # If `i` is a leaf and `len(removed_nodes) < k`, we remove `i`.\n    #     # If `i` is not a leaf, we don't remove it (yet).\n    #     # This is still not right. We need to process nodes based on current degrees.\n\n    # The standard \"leaf-peeling\" algorithm for finding a largest connected component:\n    # 1. Calculate initial degrees for all nodes.\n    # 2. Initialize a queue with all leaves (degree 1 nodes).\n    # 3. While `k` removals are still needed AND queue is not empty:\n    #    Pop a node `u` from queue.\n    #    If `u` is `n` (the most valuable node) AND we have `k-1` nodes removed already AND `n-k` nodes are remaining:\n    #      We are at the point where we need to remove one more node to reach `n-k` nodes.\n    #      If `u` is `n`, we should NOT remove it if possible.\n    #      This means we need to find another node to remove.\n    #      But `u` is popped because it's the smallest index leaf.\n    #      This means all other available leaves have larger indices than `u`.\n    #      If `u` is `n`, and it's the `k`-th node to remove, we must remove it.\n    #      This logic is flawed.\n\n    # The correct leaf-peeling algorithm for \"remove k nodes, maximize sum of remaining connected component\":\n    # 1. Initialize `current_degree` for all nodes.\n    # 2. `removed_nodes = set()`.\n    # 3. `removable_queue = collections.deque()`.\n    # 4. For `i` from `1` to `n-1`: # `n` is never a candidate for initial removal\n    #    If `current_degree[i] == 1`:\n    #      `removable_queue.append(i)`\n\n    # 5. `num_removed = 0`.\n    # 6. While `num_removed < k` and `removable_queue`:\n    #    `u = removable_queue.popleft()`\n    #    If `u` is already marked for removal, continue (this shouldn't happen with `deque` and `set`).\n    #    If `u` is `n`, we don't remove it unless forced (i.e., it's the only remaining node to make `n-k` nodes).\n    #    The condition `nodes_to_keep_count > n - k` is what matters.\n\n    #    This means we are removing nodes to reach `n-k` nodes.\n    #    We remove `u`. Add `u` to `removed_nodes`. `num_removed += 1`.\n    #    For each neighbor `v` of `u`:\n    #      If `v` not in `removed_nodes`:\n    #        `current_degree[v] -= 1`.\n    #        If `current_degree[v] == 1` and `v` != n: # `n` is special, we don't add it to queue unless forced\n    #          `removable_queue.append(v)`\n\n    # 7. After the loop, if `num_removed < k`:\n    #    This means we ran out of leaves (except possibly `n`).\n    #    The remaining graph is a path or cycle, and `n` is still there.\n    #    We still need to remove `k - num_removed` more nodes.\n    #    These nodes must be removed from the interior of the graph.\n    #    Since we want to maximize sum, we should remove the smallest indexed nodes from the remaining graph.\n    #    We iterate from `i = 1` to `n`. If `i` is not in `removed_nodes` and `num_removed < k`:\n    #      Add `i` to `removed_nodes`. `num_removed += 1`.\n\n    # Let's try this leaf-peeling strategy with the special handling for `n`.\n    # `current_degree = [0] * (n + 1)`\n    # For `u` from `1` to `n`:\n    #   `current_degree[u] = len(adj[u])`\n\n    # `q = collections.deque()`\n    # For `i` from `1` to `n`:\n    #   If `current_degree[i] == 1`:\n    #     `q.append(i)`\n\n    # `removed_nodes = [False] * (n + 1)`\n    # `removed_count = 0`\n\n    # While `q` and `removed_count < k`:\n    #   `u = q.popleft()`\n\n    #   If `removed_nodes[u]`: # Already processed/removed\n    #     continue\n\n    #   # Check if `u` is `n` and if removing it would leave exactly `n-k` nodes.\n    #   # If `u == n` and `n - removed_count == n - k + 1` (i.e., we are about to remove the `k`-th node)\n    #   # AND `u` is the only node left in the queue that is not `n`,\n    #   # then we must remove `n`.\n    #   # But we should prioritize removing smaller indices.\n    #   # If `u == n` and `n - removed_count == n - k + 1` and `q` is empty (no other choice), then remove `n`.\n    #   # Otherwise, if `u == n`, we try to defer its removal.\n    #   # This means we should re-add `n` to the end of the queue if possible, and process other nodes.\n    #   # But `q` is sorted by index. So `n` will always be the largest index in `q`.\n\n    #   # The condition for removing `u`:\n    #   # If `u != n` OR (`u == n` AND `n - removed_count == n - k + 1` AND `q` is empty)\n    #   # The second part of the OR condition: if `n` is the only remaining leaf and we need to remove one more.\n    #   # This logic is exactly what we need.\n    #   # We only remove `n` if `n - removed_count` is exactly `n-k+1` and `n` is the only remaining leaf.\n    #   # In other words, `n` is the only choice to make the graph size `n-k`.\n\n    #   # If `u == n` and `n - removed_count == n - k + 1`:\n    #   #   This means we currently have `n-k+1` nodes (not removed).\n    #   #   We need to remove one more node to reach `n-k`.\n    #   #   If `u` is `n`, and it's a leaf, it's a candidate for removal.\n    #   #   But `n` has the highest value. We should try to keep it.\n    #   #   So, if `u == n` AND there are other nodes in `q` that are not `n`, we should process them first.\n    #   #   This means `q` should be a min-heap, not a deque.\n\n    import heapq\n    import collections\n\n    current_degree = [0] * (n + 1)\n    for u in range(1, n + 1):\n        current_degree[u] = len(adj[u])\n\n    # Min-heap for leaves, ordered by index\n    q = []\n    for i in range(1, n + 1):\n        if current_degree[i] == 1:\n            heapq.heappush(q, i)\n\n    removed_nodes = [False] * (n + 1)\n    removed_count = 0\n    nodes_remaining = n\n\n    while q and removed_count < k:\n        u = heapq.heappop(q)\n\n        if removed_nodes[u]:\n            continue\n\n        # If `u` is the node `n`, and we are about to remove the `k`-th node\n        # (meaning `nodes_remaining` is `n-k+1`), we should try to keep `n`.\n        # So, if `u == n` AND `nodes_remaining == n - k + 1`:\n        # This implies `n` is the last node we can remove to get to `n-k` nodes.\n        # If `q` is empty after popping `n`, it means `n` was the only leaf.\n        # In this case, we MUST remove `n` to satisfy `k` removals.\n        # Otherwise, if `q` is not empty, it means there are other leaves (with larger indices)\n        # that we could remove instead of `n`. This is not possible because `q` is a min-heap.\n        # So, if `u == n` and `nodes_remaining == n - k + 1`, we must remove `n`.\n\n        # The only special case for `n`: if `n` is the node with the highest index,\n        # we only remove it if we have no other choice.\n        # This means `nodes_remaining` must be exactly `n-k+1`, AND `n` is the smallest index leaf available.\n        # This means `u` is `n`.\n        # If `u == n` and `nodes_remaining == n - k + 1`:\n        #   This is the critical check. We are trying to remove the `k`-th node.\n        #   If `u` is `n`, and it's the smallest index leaf available, we would remove it.\n        #   But we want to keep `n`. So, if we remove `n`, we will have `n-k` nodes.\n        #   If we don't remove `n`, we will have `n-k+1` nodes and `k-1` removed.\n        #   We need to remove `k` nodes. So, if `u` is `n` and `nodes_remaining == n-k+1`,\n        #   and we have no other options (i.e. `q` is empty), we must remove `n`.\n        #   But `q` contains all leaves. If `n` is popped, it's the smallest index leaf.\n        #   So if `n` is popped, it means it's the smallest index leaf.\n\n        # The actual condition for not removing `n`:\n        # If `u == n` and `nodes_remaining > n - k`:\n        #   This means we still have more than `n-k` nodes.\n        #   We need to remove `k - removed_count` more nodes.\n        #   If `u == n`, we should *not* remove it if there are other leaves available.\n        #   Since `q` is a min-heap, `u` is the smallest index leaf.\n        #   So if `u == n`, it means `n` is the smallest index leaf.\n        #   This can only happen if all other nodes have degree > 1, or are already removed.\n        #   If `u == n` and `nodes_remaining > n - k`:\n        #     We should defer removing `n` if possible.\n        #     If `q` is empty, then `n` is the only remaining leaf. We *must* remove `n`.\n        #     If `q` is not empty, then there are other leaves. But `u` is the smallest.\n        #     This means `u` is not `n` if there are other leaves.\n        #     So, if `u == n`, it must be the case that `n` is the smallest index leaf.\n        #     We only remove `n` if `nodes_remaining == n - k + 1`.\n\n        # The logic:\n        # If `u == n` and `nodes_remaining == n - k + 1`:\n        #   This means we are about to remove the `k`-th node.\n        #   If we remove `n`, we will have `n-k` nodes. This satisfies the size constraint.\n        #   Since `n` has the highest value, we want to keep it.\n        #   So, if `u == n` is popped, and `nodes_remaining` is `n-k+1`, it means we have `k-1` nodes removed.\n        #   We need to remove one more. If `n` is the smallest index leaf available, we would remove it.\n        #   But this is exactly the point where we want to avoid removing `n`.\n        #   So, we must find another node to remove.\n        #   This means we should re-add `n` to the queue and try to find another node.\n        #   But this is not how leaf peeling works.\n\n        # The problem asks to remove `k` nodes.\n        # The key idea: the `n-k` nodes we keep form a connected component.\n        # The nodes that are *not* in this component are the `k` nodes to be removed.\n        # We want to remove the `k` nodes with the smallest indices.\n        # This implies we should prioritize removing leaves with smallest indices.\n        # The only exception is if removing a leaf prevents us from having `n-k` nodes remaining.\n\n        # The condition is simpler: we can remove `u` if `nodes_remaining - 1 >= n - k`.\n        # This is always true as long as `nodes_remaining > n - k`.\n        # The only special case is `u == n`. We want to keep `n` if possible.\n        # So, if `u == n` and `nodes_remaining > n - k`, we should try to avoid removing `n`.\n        # This means we should skip `n` for now and try to remove other leaves.\n        # But `q` is a min-heap. If `n` is popped, it's the smallest index leaf.\n        # This means all other available leaves have indices greater than `n`, which is impossible.\n        # So, if `n` is popped, it means `n` is the *only* leaf left (or all other leaves are already removed).\n\n        # The correct logic for leaf peeling with special node `n`:\n        # We have `nodes_remaining` nodes. We want to reach `n-k` nodes.\n        # This means we need to remove `nodes_remaining - (n-k)` more nodes.\n        # Let `target_removals = nodes_remaining - (n-k)`.\n        # If `u == n` AND `target_removals == 1`:\n        #   This means `n` is the last node to be removed to reach the target size.\n        #   We want to avoid removing `n`.\n        #   So, if `u == n` and `nodes_remaining == n - k + 1`:\n        #     We must *not* remove `n` if there are other nodes to remove.\n        #     But `u` is the smallest index leaf.\n        #     So, if `u == n`, and `nodes_remaining == n - k + 1`, we must remove `n`.\n        #     This logic is wrong.\n\n        # The correct logic is: we are allowed to remove `k` nodes.\n        # We have `n` nodes. We want to remove `k` nodes.\n        # We always try to remove the smallest indexed leaf.\n        # The only exception is node `n`. We want to keep `n`.\n        # So, if `u == n` is popped from `q`, we check `removed_count`.\n        # If `removed_count < k`, we want to avoid removing `n`.\n        # We should put `n` back into `q` and break the loop.\n        # This means `n` is the *only* remaining leaf, and we are not forced to remove it yet.\n        # All other nodes have degree > 1.\n        # If we cannot remove `n`, and we still need to remove more nodes,\n        # it means we have to remove an internal node.\n        # This is where the leaf-peeling breaks down for general graphs.\n        # But for trees, there are always at least two leaves (unless `n=1`).\n        # So, if `n` is a leaf and `n>1`, there must be at least one other leaf.\n        # So, `n` will not be popped if there are other smaller leaves.\n\n        # The logic should be:\n        # If `u == n`:\n        #   If `nodes_remaining - 1 == n - k`: # i.e., `n` is the (n-k+1)-th node\n        #     # We are about to remove the node that would bring the count to `n-k`.\n        #     # This means we have `k-1` nodes already removed.\n        #     # If we remove `n`, we will have `k` nodes removed.\n        #     # This is the last removal needed.\n        #     # We should keep `n` if possible.\n        #     # If `q` is empty, it means `n` is the only leaf. We must remove `n`.\n        #     # If `q` is not empty, it means there are other leaves (with larger indices, since `u` is `n`).\n        #     # This is impossible, as `q` is a min-heap.\n        #     # So, if `u == n` is popped, and `nodes_remaining == n-k+1`, it means `n` is the smallest index leaf.\n        #     # This can only happen if `n` is the only leaf left.\n        #     # So, if `u == n` and `nodes_remaining == n-k+1`, we must remove `n`.\n        #     # This logic is exactly what we want to AVOID.\n\n        # The correct way to handle `n`:\n        # When `u` is popped from `q`:\n        # If `u == n` AND `nodes_remaining == n - k + 1`:\n        #   # This means we have `n-k+1` nodes currently, and `n` is the smallest index leaf.\n        #   # We need to remove one more node to reach `n-k` nodes.\n        #   # If we remove `n`, we get `n-k` nodes. This satisfies the size.\n        #   # But `n` is the most valuable.\n        #   # So, we should *not* remove `n`. We keep `n`.\n        #   # This implies we cannot remove `k` nodes by only peeling leaves.\n        #   # This means the remaining `k - removed_count` nodes must be chosen from the remaining internal nodes.\n        #   # So, we put `n` back, and break the loop.\n        #   heapq.heappush(q, u)\n        #   break # Stop peeling leaves. We need to remove internal nodes now.\n\n        # Otherwise (if `u != n` OR `nodes_remaining > n - k + 1`):\n        #   Remove `u`.\n        #   `removed_nodes[u] = True`\n        #   `removed_count += 1`\n        #   `nodes_remaining -= 1`\n        #   For each neighbor `v` of `u`:\n        #     If `not removed_nodes[v]`:\n        #       `current_degree[v] -= 1`\n        #       If `current_degree[v] == 1`:\n        #         `heapq.heappush(q, v)`\n\n    # Let's re-trace Example 2 with this refined leaf-peeling:\n    # N=8, K=4. Keep 4 nodes. `n-k = 4`.\n    # `current_degree`: 1:2, 2:4, 3:1, 4:1, 5:1, 6:1, 7:3, 8:1\n    # Initial `q`: [1, 3, 4, 5, 6, 8] (all leaves).\n    # `removed_nodes = [F]*9`. `removed_count = 0`. `nodes_remaining = 8`.\n\n    # Loop 1: `q = [1, 3, 4, 5, 6, 8]`. `removed_count = 0 < 4`.\n    #   `u = 1`. `u != n`. `nodes_remaining = 8 > n-k+1 = 5`. Remove 1.\n    #   `removed_nodes[1]=T`. `removed_count = 1`. `nodes_remaining = 7`.\n    #   Neighbor of 1: `v = 2`. `current_degree[2] = 3`.\n    #   `q = [3, 4, 5, 6, 8]`.\n\n    # Loop 2: `q = [3, 4, 5, 6, 8]`. `removed_count = 1 < 4`.\n    #   `u = 3`. `u != n`. `nodes_remaining = 7 > 5`. Remove 3.\n    #   `removed_nodes[3]=T`. `removed_count = 2`. `nodes_remaining = 6`.\n    #   Neighbor of 3: `v = 1`. `removed_nodes[1]=T`. Skip.\n    #   `q = [4, 5, 6, 8]`.\n\n    # Loop 3: `q = [4, 5, 6, 8]`. `removed_count = 2 < 4`.\n    #   `u = 4`. `u != n`. `nodes_remaining = 6 > 5`. Remove 4.\n    #   `removed_nodes[4]=T`. `removed_count = 3`. `nodes_remaining = 5`.\n    #   Neighbor of 4: `v = 2`. `current_degree[2] = 2`.\n    #   `q = [5, 6, 8]`.\n\n    # Loop 4: `q = [5, 6, 8]`. `removed_count = 3 < 4`.\n    #   `u = 5`. `u != n`. `nodes_remaining = 5 == n-k+1`.\n    #   This is the critical step. `u = 5`. `nodes_remaining = 5`. `n-k+1 = 5`.\n    #   We are about to remove the `k`-th node (which is 5).\n    #   The condition `u == n` and `nodes_remaining == n-k+1` is `5 == 8` (False).\n    #   So we remove 5.\n    #   `removed_nodes[5]=T`. `removed_count = 4`. `nodes_remaining = 4`.\n    #   Neighbor of 5: `v = 7`. `current_degree[7] = 2`.\n    #   `q = [6, 8]`.\n\n    # Loop ends because `removed_count == k` (4 == 4).\n\n    # Final `removed_nodes` are `1, 3, 4, 5`.\n    # This matches the example output! This strategy is correct.\n\n    # What if `n=1`? `k=0` is not allowed. `k < n`. So `n >= 2`.\n    # What if `n` is a leaf, and it's removed?\n    # The condition `if u == n and nodes_remaining == n - k + 1:`\n    # This condition should be: `if u == n and nodes_remaining == n - k + 1:`\n    # Then `heapq.heappush(q, u)` and `break`.\n    # This means we are deferring the removal of `n`.\n    # If `removed_count < k` after the loop, it means we must remove more nodes.\n    # These additional nodes must be chosen from the remaining `nodes_remaining` nodes.\n    # We should choose the smallest indexed ones.\n\n    # Let's refine the loop termination:\n    # The `while q and removed_count < k` loop runs.\n    # If it breaks because `q` is empty, it means we ran out of leaves.\n    # If it breaks because `removed_count == k`, we are done.\n\n    # If `q` becomes empty, and `removed_count < k`:\n    #   This means all remaining nodes have degree >= 2 (they form a cycle or a path).\n    #   And `n` is among these nodes (because we deferred its removal).\n    #   We need to remove `k - removed_count` more nodes.\n    #   We should remove the smallest indexed nodes from the remaining graph.\n    #   These nodes are `i` such that `removed_nodes[i]` is `False`.\n    #   Iterate `i` from `1` to `n`. If `not removed_nodes[i]` and `removed_count < k`, remove `i`.\n\n    # This is the full algorithm.\n\n    # Implementation details:\n    # `adj` list.\n    # `current_degree` array.\n    # `q` (min-heap).\n    # `removed_nodes` boolean array.\n    # `removed_count`.\n    # `nodes_remaining`.\n\n    # Initializing `q`:\n    q = []\n    for i in range(1, n + 1):\n        if current_degree[i] == 1:\n            heapq.heappush(q, i)\n\n    # Main loop for leaf peeling\n    while q and removed_count < k:\n        u = heapq.heappop(q)\n\n        if removed_nodes[u]:\n            continue\n\n        # Special handling for node `n`\n        if u == n and nodes_remaining == n - k + 1:\n            # If `n` is the smallest index leaf available, and removing it\n            # would bring us to exactly `n-k` nodes, we should keep `n`.\n            # So, we put `n` back and stop peeling leaves.\n            heapq.heappush(q, u)\n            break\n\n        # Remove `u`\n        removed_nodes[u] = True\n        removed_count += 1\n        nodes_remaining -= 1\n\n        # Update degrees of neighbors\n        for v in adj[u]:\n            if not removed_nodes[v]:\n                current_degree[v] -= 1\n                if current_degree[v] == 1:\n                    heapq.heappush(q, v)\n\n    # If we still need to remove more nodes after peeling all possible leaves (or deferring `n`):\n    if removed_count < k:\n        for i in range(1, n + 1):\n            if not removed_nodes[i] and removed_count < k:\n                removed_nodes[i] = True\n                removed_count += 1\n            if removed_count == k:\n                break\n\n    # Collect the indices of removed nodes in increasing order\n    result = []\n    for i in range(1, n + 1):\n        if removed_nodes[i]:\n            result.append(i)\n\n    sys.stdout.write(\" \".join(map(str, result)) + \"\\n\")\n\nsolve()"}
{"task_id": "E2H_CF1709F", "completion": "import sys\n\nsys.setrecursionlimit(10**6)\ninput = sys.stdin.readline\nMOD = 998244353\n\n\ndef solve():\n  n, k, f = map(int, input().split())\n\n  dp = [[0] * (k + 1) for _ in range(n + 1)]\n  dp[0][0] = 1\n\n  for i in range(1, n + 1):\n    for j in range(k + 1):\n      for prev_val in range(j + 1):\n        if j - prev_val * 2 <= k and j - prev_val * 2 >= 0:\n          dp[i][j] = (dp[i][j] + dp[i - 1][j - prev_val * 2]) % MOD\n\n  ans = 0\n  for x in range(f + 1):\n    if x <= k and f - x <= k:\n      ans = (ans + dp[n][x] * dp[n][f - x]) % MOD\n\n  print(ans)\n\n\nif __name__ == '__main__':\n  solve()"}
