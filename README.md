# E2H-Codeforces Evaluation Toolkit

A comprehensive evaluation framework for testing AI models on 60 competitive programming problems from Codeforces using multiple prompt variants and I/O-based testing.

## ğŸ¯ What This Code Does

This toolkit evaluates AI models on competitive programming by:

- **Problem Testing**: Tests 5 AI models (GPT-5 Mini, Gemini 2.5 Flash, Qwen3-14B, DeepSeek variants) on 60 Codeforces problems
- **Variant Analysis**: Uses 18 different prompt variants per problem (3 difficulty levels Ã— 6 complexity levels) to find optimal prompting strategies
- **Comprehensive Evaluation**: Runs 21,600 total evaluations (5 models Ã— 4 years Ã— 60 problems Ã— 18 variants) with sandboxed code execution
- **Performance Analysis**: Generates detailed visualizations showing pass rates, failure modes, and optimal prompt variants per model

## ğŸ“Š Key Results

**Best performing models:** Gemini 2.5 Flash (60.1% pass rate) and GPT-5 Mini (59.4% pass rate) significantly outperform others. **Medium difficulty prompts** consistently work best across all models, while "none" (no difficulty specified) prompts perform worst. The evaluation achieved 100% score coverage across all 21,600 test cases.

## ğŸš€ Quick Start

```bash
cd e2h_eval
python3 scripts/run_full_variant_evaluation.py  # Run complete evaluation
python3 scripts/variant_analysis.py             # Generate performance heatmaps  
python3 scripts/improved_failure_analysis.py    # Analyze failure patterns
```

## ğŸ“ Repository Structure

```
e2h_eval/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ E2H-Codeforces.json      # 60 problems dataset
â”‚   â””â”€â”€ eval_202*/               # Evaluation logs (21,600 files)
â”œâ”€â”€ problems/
â”‚   â””â”€â”€ e2h_problems.jsonl       # Problem definitions
â”œâ”€â”€ samples/
â”‚   â””â”€â”€ *_variants.jsonl         # Extracted samples (20 files)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ *_results.jsonl          # Evaluation results (20 files)
â”‚   â”œâ”€â”€ variant_heatmap_*.png    # Performance heatmaps
â”‚   â””â”€â”€ failure_mode_*.png       # Failure analysis charts
â””â”€â”€ scripts/
    â”œâ”€â”€ run_full_variant_evaluation.py  # Main evaluation pipeline
    â”œâ”€â”€ variant_analysis.py             # Performance analysis
    â””â”€â”€ improved_failure_analysis.py    # Failure mode analysis
```
